{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from collections import defaultdict\n",
    "from timeit import default_timer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeConstraint:\n",
    "\n",
    "    def __init__(self, end_dt, start_dt=None):\n",
    "        \"\"\"\n",
    "        When end_dt is only given, system will have a max time constraint only.\n",
    "\n",
    "        When end_dt and start_dt are given, system will have beginning end ending boundary.\n",
    "\n",
    "        :param end_dt: The maximum limit of the time constraint.\n",
    "        :param start_dt: The minimum limit of the time constraint.\n",
    "            Always set start_dt to None if you change the object from time_bin to max_limit.\n",
    "        \"\"\"\n",
    "        self.end_dt = end_dt\n",
    "        self.start_dt = start_dt\n",
    "\n",
    "    def is_valid_time_bin(self) -> bool:\n",
    "        \"\"\"\n",
    "        Check whether this TimeConstraint object represents a valid time bin.\n",
    "        \"\"\"\n",
    "        if self.is_time_bin() and (self._end_dt > self._start_dt):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def is_valid_max_limit(self) -> bool:\n",
    "        \"\"\"\n",
    "        Check whether this TimeConstraint represents a valid max time limit.\n",
    "        \"\"\"\n",
    "        if (self._end_dt is not None) and (self._start_dt is None):\n",
    "            return True\n",
    "\n",
    "    def is_time_bin(self) -> bool:\n",
    "        if (self._start_dt is not None) and (self._end_dt is not None):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    # Comparing TimeConstraints\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if other is None:\n",
    "            return False\n",
    "        return self._start_dt == other.start_dt and self._end_dt == other.end_dt\n",
    "\n",
    "    def __ne__(self, other):\n",
    "        if other is None:\n",
    "            return False\n",
    "        return self._start_dt != other.start_dt or self._end_dt != other.end_dt\n",
    "\n",
    "    # Properties\n",
    "\n",
    "    @property\n",
    "    def end_dt(self):\n",
    "        return self._end_dt\n",
    "\n",
    "    @end_dt.setter\n",
    "    def end_dt(self, value):\n",
    "        self._end_dt = value\n",
    "\n",
    "    @property\n",
    "    def start_dt(self):\n",
    "        return self._start_dt\n",
    "\n",
    "    @start_dt.setter\n",
    "    def start_dt(self, value):\n",
    "        self._start_dt = value\n",
    "\n",
    "    # Printing TimeConstraints\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"(start = {self._start_dt}, end= {self._end_dt})\"\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"(start = {self._start_dt}, end= {self._end_dt})\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cache:\n",
    "\n",
    "    def __init__(self,\n",
    "                 is_ratings_cached=False,\n",
    "                 ratings=None,\n",
    "                 is_movies_cached=False,\n",
    "                 movies=None,\n",
    "                 is_movie_ratings_cached=False,\n",
    "                 movie_ratings=None,\n",
    "                 is_user_movie_matrix_cached=False,\n",
    "                 user_movie_matrix=None,\n",
    "                 is_user_correlations_cached=False,\n",
    "                 user_correlations=None,\n",
    "                 min_common_elements=5,\n",
    "                 use_avg_ratings_cache=True):\n",
    "        \"\"\" Cached data is only valid when the boolean specifier is True \"\"\"\n",
    "\n",
    "        # 30% performance\n",
    "        self.is_ratings_cached = is_ratings_cached\n",
    "        self.ratings = ratings\n",
    "\n",
    "        # 7 fold performance gain on 'movie' related queries\n",
    "        self.is_movies_cached = is_movies_cached\n",
    "        self.movies = movies\n",
    "\n",
    "        self.is_movie_ratings_cached = is_movie_ratings_cached\n",
    "        self.movie_ratings = movie_ratings\n",
    "\n",
    "        self.is_user_movie_matrix_cached = is_user_movie_matrix_cached\n",
    "        self.user_movie_matrix = user_movie_matrix\n",
    "\n",
    "        self.is_user_correlations_cached = is_user_correlations_cached\n",
    "        self.user_correlations = user_correlations\n",
    "\n",
    "        self.min_common_elements = min_common_elements\n",
    "\n",
    "        # if use avg ratings cache, on average 10 fold performance gain\n",
    "        self.use_avg_ratings_cache = use_avg_ratings_cache\n",
    "        if self.use_avg_ratings_cache:\n",
    "            self.avg_user_ratings = self.create_user_avg_rating_cache()\n",
    "        else:\n",
    "            self.avg_user_ratings = None\n",
    "\n",
    "    def create_user_avg_rating_cache(self):\n",
    "        if self.is_ratings_cached:\n",
    "            data = self.ratings\n",
    "        else:\n",
    "            data = self.movie_ratings\n",
    "        return data.groupby('user_id')[['rating']].mean()\n",
    "\n",
    "    def get_user_corrs(self, min_common_elements, time_constraint=None):\n",
    "        \"\"\"\n",
    "        If cached returns the cache, else none\n",
    "        :param min_common_elements: min common element in between users in order them to become neighbours\n",
    "        :param time_constraint: used in temporal caches only, None in this context\n",
    "        :return: user correlation matrix if cache found, else None\n",
    "        \"\"\"\n",
    "        if self.is_user_correlations_cached:\n",
    "            if self.min_common_elements == min_common_elements:\n",
    "                return self.user_correlations\n",
    "        return None\n",
    "\n",
    "    # Properties\n",
    "    @property\n",
    "    def ratings(self):\n",
    "        return self._ratings\n",
    "\n",
    "    @ratings.setter\n",
    "    def ratings(self, value):\n",
    "        self._ratings = value\n",
    "\n",
    "    @property\n",
    "    def movies(self):\n",
    "        return self._movies\n",
    "\n",
    "    @movies.setter\n",
    "    def movies(self, value):\n",
    "        self._movies = value\n",
    "\n",
    "    @property\n",
    "    def movie_ratings(self):\n",
    "        return self._movie_ratings\n",
    "\n",
    "    @movie_ratings.setter\n",
    "    def movie_ratings(self, value):\n",
    "        self._movie_ratings = value\n",
    "\n",
    "    @property\n",
    "    def user_movie_matrix(self):\n",
    "        return self._user_movie_matrix\n",
    "\n",
    "    @user_movie_matrix.setter\n",
    "    def user_movie_matrix(self, value):\n",
    "        self._user_movie_matrix = value\n",
    "\n",
    "    @property\n",
    "    def user_correlations(self):\n",
    "        return self._user_correlations\n",
    "\n",
    "    @user_correlations.setter\n",
    "    def user_correlations(self, value):\n",
    "        self._user_correlations = value\n",
    "\n",
    "    @property\n",
    "    def min_common_elements(self):\n",
    "        return self._min_common_elements\n",
    "\n",
    "    @min_common_elements.setter\n",
    "    def min_common_elements(self, value):\n",
    "        self._min_common_elements = value\n",
    "\n",
    "\n",
    "class TemporalCache(Cache):\n",
    "\n",
    "    def __init__(self,\n",
    "                 time_constraint: TimeConstraint,\n",
    "                 is_ratings_cached=False,\n",
    "                 ratings=None,\n",
    "                 is_movies_cached=False,\n",
    "                 movies=None,\n",
    "                 is_movie_ratings_cached=False,\n",
    "                 movie_ratings=None,\n",
    "                 is_user_movie_matrix_cached=False,\n",
    "                 user_movie_matrix=None,\n",
    "                 is_user_correlations_cached=False,\n",
    "                 user_correlations=None,\n",
    "                 min_common_elements=5,\n",
    "                 use_avg_ratings_cache=True,\n",
    "                 use_bulk_corr_cache=True):\n",
    "\n",
    "        super().__init__(is_ratings_cached=is_ratings_cached,\n",
    "                         ratings=ratings,\n",
    "                         is_movies_cached=is_movies_cached,\n",
    "                         movies=movies,\n",
    "                         is_movie_ratings_cached=is_movie_ratings_cached,\n",
    "                         movie_ratings=movie_ratings,\n",
    "                         is_user_movie_matrix_cached=is_user_movie_matrix_cached,\n",
    "                         user_movie_matrix=user_movie_matrix,\n",
    "                         is_user_correlations_cached=is_user_correlations_cached,\n",
    "                         user_correlations=user_correlations,\n",
    "                         min_common_elements=min_common_elements,\n",
    "                         use_avg_ratings_cache=use_avg_ratings_cache)\n",
    "\n",
    "        self.time_constraint = time_constraint\n",
    "        self.use_bulk_corr_cache = use_bulk_corr_cache\n",
    "        self.user_corrs_in_bulk = None\n",
    "\n",
    "    def is_temporal_cache_valid(self):\n",
    "        # No TimeConstraint, valid\n",
    "        if self._time_constraint is None:\n",
    "            return True\n",
    "        # Bin TimeConstraint or Max Limit TimeConstraint, valid\n",
    "        if self._time_constraint.is_valid_time_bin() or self._time_constraint.is_valid_max_limit():\n",
    "            return True\n",
    "        # Else, Not Valid\n",
    "        return False\n",
    "\n",
    "    def get_user_corrs_from_bulk(self, min_common_elements, time_constraint, bin_size):\n",
    "        if ((self.user_corrs_in_bulk is None) or (self.user_corrs_in_bulk is None)\n",
    "                or (time_constraint is None) or self.min_common_elements != min_common_elements):\n",
    "            return None\n",
    "\n",
    "        if time_constraint.is_valid_max_limit():\n",
    "            return self.user_corrs_in_bulk.get(time_constraint.end_dt.year)\n",
    "\n",
    "        if bin_size == -1:\n",
    "            return None\n",
    "\n",
    "        bins = self.user_corrs_in_bulk.get(bin_size)\n",
    "        if bins is not None:\n",
    "            return bins.get(time_constraint.start_dt.year)\n",
    "\n",
    "    def get_user_corrs(self, min_common_elements, time_constraint=None):\n",
    "        \"\"\"\n",
    "        If cached returns the cache, else none\n",
    "\n",
    "        :param min_common_elements: min common element in between users in order them to become neighbours\n",
    "        :param time_constraint: time constraint on user correlations\n",
    "        :return: user correlation matrix if cache found, else None\n",
    "        \"\"\"\n",
    "        if self.is_user_correlations_cached:\n",
    "            if self.time_constraint == time_constraint and self.min_common_elements == min_common_elements:\n",
    "                return self.user_correlations\n",
    "        return None\n",
    "\n",
    "    def set_user_corrs(self, user_corrs, min_common_elements, time_constraint):\n",
    "        # Only set when caching is open for user_correlations\n",
    "        if self.is_user_correlations_cached:\n",
    "            self._time_constraint = time_constraint\n",
    "            self.min_common_elements = min_common_elements\n",
    "            self.user_correlations = user_corrs\n",
    "\n",
    "    @property\n",
    "    def time_constraint(self):\n",
    "        return self._time_constraint\n",
    "\n",
    "    @time_constraint.setter\n",
    "    def time_constraint(self, value):\n",
    "        self._time_constraint = value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accuracy:\n",
    "\n",
    "    @staticmethod\n",
    "    def rmse(predictions) -> float:\n",
    "        if type(predictions) is pd.DataFrame:\n",
    "            number_of_predictions = 0\n",
    "            sum_of_square_differences = 0.0\n",
    "            for row in predictions.itertuples(index=False):\n",
    "                # row[1] : actual rating, row[0] : prediction\n",
    "                prediction = row[0]\n",
    "                if prediction != 0:\n",
    "                    sum_of_square_differences += (row[1] - prediction) ** 2\n",
    "                    number_of_predictions += 1\n",
    "            return sum_of_square_differences / number_of_predictions if number_of_predictions != 0 else 0\n",
    "        elif type(predictions) is list:\n",
    "            number_of_predictions = 0\n",
    "            sum_of_square_differences = 0.0\n",
    "            for prediction, actual in predictions:\n",
    "                if prediction != 0:\n",
    "                    sum_of_square_differences += (actual - prediction) ** 2\n",
    "                    number_of_predictions += 1\n",
    "            return sum_of_square_differences / number_of_predictions if number_of_predictions != 0 else 0\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(ABC):\n",
    "    @staticmethod\n",
    "    @abstractmethod\n",
    "    def load():\n",
    "        \"\"\" Every subclass must provide static load method\"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 ratings_col_names=('user_id', 'item_id', 'rating', 'timestamp'),\n",
    "                 ratings_path=r'C:\\Users\\Yukawa\\datasets\\ml-latest-small\\ratings.csv',\n",
    "                 movies_col_names=('item_id', 'title', 'genres'),\n",
    "                 movies_path=r'C:\\Users\\Yukawa\\datasets\\ml-latest-small\\movies.csv',\n",
    "                 is_ratings_cached=True,\n",
    "                 is_movies_cached=True):\n",
    "        Dataset.__init__(self)\n",
    "        self.is_ratings_cached = is_ratings_cached\n",
    "        self.is_movies_cached = is_movies_cached\n",
    "        self.ratings = MovieLensDataset.load_ratings(ratings_path,\n",
    "                                                     ratings_col_names) if self.is_ratings_cached else None\n",
    "        self.movies = MovieLensDataset.load_movies(movies_path,\n",
    "                                                   movies_col_names) if self.is_movies_cached else None\n",
    "\n",
    "    @staticmethod\n",
    "    def load_movies(movies_path,\n",
    "                    movies_col_names=('item_id', 'title', 'genres')):\n",
    "        if not os.path.isfile(movies_path) or not movies_col_names:\n",
    "            return None\n",
    "\n",
    "        # read movies\n",
    "        movies = pd.read_csv(movies_path, sep=',', header=1, names=movies_col_names)\n",
    "\n",
    "        # Extract Movie Year\n",
    "        movies['year'] = movies.title.str.extract(\"\\((\\d{4})\\)\", expand=True)\n",
    "        movies.year = pd.to_datetime(movies.year, format='%Y')\n",
    "        movies.year = movies.year.dt.year  # As there are some NaN years, resulting type will be float (decimals)\n",
    "\n",
    "        # Remove year part from the title\n",
    "        movies.title = movies.title.str[:-7]\n",
    "\n",
    "        return movies\n",
    "\n",
    "    @staticmethod\n",
    "    def load_ratings(ratings_path,\n",
    "                     ratings_col_names=('user_id', 'item_id', 'rating', 'timestamp')):\n",
    "        if not os.path.isfile(ratings_path) or not ratings_col_names:\n",
    "            return None\n",
    "\n",
    "        # read ratings\n",
    "        ratings = pd.read_csv(ratings_path, sep=',', header=1, names=ratings_col_names)\n",
    "\n",
    "        # Convert timestamp into readable format\n",
    "        ratings['timestamp'] = pd.to_datetime(ratings['timestamp'], unit='s', origin='unix')\n",
    "\n",
    "        return ratings\n",
    "\n",
    "    @staticmethod\n",
    "    def create_movie_ratings(ratings, movies):\n",
    "        return pd.merge(ratings, movies, on='item_id')\n",
    "\n",
    "    @staticmethod\n",
    "    def load(ratings_col_names=('user_id', 'item_id', 'rating', 'timestamp'),\n",
    "             ratings_path=r'C:\\Users\\Yukawa\\datasets\\ml-latest-small\\ratings.csv',\n",
    "             movies_col_names=('item_id', 'title', 'genres'),\n",
    "             movies_path=r'C:\\Users\\Yukawa\\datasets\\ml-latest-small\\movies.csv'\n",
    "             ):\n",
    "        # Load movies\n",
    "        movies = MovieLensDataset.load_movies(movies_path=movies_path, movies_col_names=movies_col_names)\n",
    "        # Load ratings\n",
    "        ratings = MovieLensDataset.load_ratings(ratings_path=ratings_path, ratings_col_names=ratings_col_names)\n",
    "\n",
    "        # Merge the ratings and movies\n",
    "        movie_ratings = pd.merge(ratings, movies, on='item_id')\n",
    "\n",
    "        return movie_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalPearson:\n",
    "\n",
    "    def __init__(self, cache: TemporalCache, time_constraint: TimeConstraint = None, min_common_elements: int = 5):\n",
    "        self.time_constraint = time_constraint\n",
    "        self.cache = cache\n",
    "        self.min_common_elements = min_common_elements\n",
    "        #from .trainset import TrainsetUser, TrainsetMovie\n",
    "        self.trainset_user = TrainsetUser(cache=self.cache)\n",
    "        self.trainset_movie = TrainsetMovie(cache=self.cache)\n",
    "\n",
    "    def mean_centered_pearson(self, user_id, movie_id, k_neighbours: pd.DataFrame) -> float:\n",
    "        \"\"\"\n",
    "        Calculate Mean Centered Prediction\n",
    "\n",
    "        :param user_id: user of interest\n",
    "        :param movie_id: the movie's rating is the one we we want to predict\n",
    "        :param k_neighbours: k nearest neighbours in DataFrame where index user_id, column correlation in between.\n",
    "        :return: Prediction rating\n",
    "        \"\"\"\n",
    "        # If a movie with movie_id not exists, predict 0\n",
    "        if self.trainset_movie.get_movie(movie_id=movie_id).empty:\n",
    "            return 0\n",
    "\n",
    "        if k_neighbours is None or k_neighbours.empty:\n",
    "            return 0\n",
    "\n",
    "        user_avg_rating = self.trainset_user.get_user_avg(user_id=user_id)\n",
    "\n",
    "        weighted_sum = 0.0\n",
    "        sum_of_weights = 0.0\n",
    "        for neighbour_id, data in k_neighbours.iterrows():\n",
    "            # Get each neighbour's correlation 'user_id' and her rating to 'movie_id'\n",
    "            neighbour_corr = data['correlation']\n",
    "            neighbour_rating = self.trainset_movie.get_movie_rating(movie_id=movie_id, user_id=neighbour_id)\n",
    "            # If the neighbour doesnt give rating to the movie_id, pass this around of the loop\n",
    "            if neighbour_rating == 0:\n",
    "                continue\n",
    "            neighbour_avg_rating = self.trainset_user.get_user_avg(user_id=neighbour_id)\n",
    "            neighbour_mean_centered_rating = neighbour_rating - neighbour_avg_rating\n",
    "            # Calculate Weighted sum and sum of weights\n",
    "            weighted_sum += neighbour_mean_centered_rating * neighbour_corr\n",
    "            sum_of_weights += neighbour_corr\n",
    "\n",
    "        # Predict\n",
    "        if sum_of_weights != 0:\n",
    "            prediction_rating = user_avg_rating + (weighted_sum / sum_of_weights)\n",
    "        else:\n",
    "            prediction_rating = 0  # In this case, none of the neighbours have given rating to 'the movie'\n",
    "\n",
    "        return prediction_rating\n",
    "\n",
    "    def get_corr_matrix(self, bin_size=-1):\n",
    "        user_corrs = None\n",
    "        # if valid cache found, try to get user corrs from there\n",
    "        if self.cache.is_temporal_cache_valid():\n",
    "            # First check user-correlations\n",
    "            user_corrs = self.cache.get_user_corrs(self.min_common_elements, self.time_constraint)\n",
    "            if user_corrs is not None:\n",
    "                return user_corrs\n",
    "            # Then check bulk-user-correlations\n",
    "            user_corrs = self.cache.get_user_corrs_from_bulk(time_constraint=self.time_constraint,\n",
    "                                                             min_common_elements=self.min_common_elements,\n",
    "                                                             bin_size=bin_size)\n",
    "            if user_corrs is not None:\n",
    "                return user_corrs\n",
    "\n",
    "        # here, if cache not found or no cache match\n",
    "\n",
    "        # Create user correlations\n",
    "        user_corrs = TemporalPearson.create_user_corrs(movie_ratings=self.cache.movie_ratings,\n",
    "                                                       time_constraint=self.time_constraint,\n",
    "                                                       min_common_elements=self.min_common_elements)\n",
    "        # Cache the user_corrs\n",
    "        self.cache.set_user_corrs(user_corrs=user_corrs,\n",
    "                                  min_common_elements=self.min_common_elements,\n",
    "                                  time_constraint=self.time_constraint)\n",
    "\n",
    "        return user_corrs\n",
    "\n",
    "    @staticmethod\n",
    "    def create_user_corrs(movie_ratings, time_constraint: TimeConstraint, min_common_elements):\n",
    "        # by default movie_ratings is for no time constraint\n",
    "        # with these controls change the time constraint of the movie_ratings\n",
    "        if time_constraint is not None:\n",
    "            if time_constraint.is_valid_max_limit():\n",
    "                movie_ratings = movie_ratings[movie_ratings.timestamp < time_constraint.end_dt]\n",
    "            elif time_constraint.is_valid_time_bin():\n",
    "                movie_ratings = movie_ratings[(movie_ratings.timestamp >= time_constraint.start_dt)\n",
    "                                              & (movie_ratings.timestamp < time_constraint.end_dt)]\n",
    "\n",
    "        user_movie_matrix = movie_ratings.pivot_table(index='title', columns='user_id', values='rating')\n",
    "        return user_movie_matrix.corr(method=\"pearson\", min_periods=min_common_elements)\n",
    "\n",
    "    def cache_user_corrs_in_bulk_for_max_limit(self, time_constraint: TimeConstraint, min_year, max_year):\n",
    "        \"\"\"\n",
    "        Cache user correlations by changing year of the time_constraint\n",
    "        for each year in between min_year and max_year(not included)\n",
    "\n",
    "        :param time_constraint: time_constraint apply\n",
    "        :param min_year: start of the range\n",
    "        :param max_year: end of the range\n",
    "        \"\"\"\n",
    "\n",
    "        if self.cache.use_bulk_corr_cache:\n",
    "            if time_constraint is not None and time_constraint.is_valid_max_limit():\n",
    "                self.cache.user_corrs_in_bulk = dict()\n",
    "                for year in range(min_year, max_year):\n",
    "                    time_constraint.end_dt = time_constraint.end_dt.replace(year=year)\n",
    "                    corrs = TemporalPearson.create_user_corrs(self.cache.movie_ratings, time_constraint,\n",
    "                                                              self.min_common_elements)\n",
    "                    self.cache.user_corrs_in_bulk[year] = corrs\n",
    "            else:\n",
    "                raise Exception(\"Trying to cache user correlations in bulk for max_limit \"\n",
    "                                \"but start time is not max_limit!\")\n",
    "        else:\n",
    "            raise Exception(\"Trying to create bulk corr cache when use_bulk_corr_cache is False\")\n",
    "\n",
    "    def cache_user_corrs_in_bulk_for_time_bins(self, time_constraint: TimeConstraint, min_year, max_year,\n",
    "                                               min_time_bin_size=2, max_time_bin_size=10):\n",
    "        if self.cache.use_bulk_corr_cache:\n",
    "            if time_constraint is not None and time_constraint.is_valid_time_bin():\n",
    "                del self.cache.user_corrs_in_bulk    # invalidate old cache\n",
    "                self.cache.user_corrs_in_bulk = dict()\n",
    "                for time_bin_size in range(min_time_bin_size, max_time_bin_size):\n",
    "                    self.cache.user_corrs_in_bulk[time_bin_size] = dict()\n",
    "                    for shift in range(0, time_bin_size):\n",
    "                        curr_year = min_year + shift\n",
    "                        while (curr_year + time_bin_size) < max_year:\n",
    "                            time_constraint = TimeConstraint(start_dt=datetime(curr_year, 1, 1),\n",
    "                                                             end_dt=datetime(curr_year + time_bin_size, 1, 1))\n",
    "                            corrs = TemporalPearson.create_user_corrs(self.cache.movie_ratings,\n",
    "                                                                      time_constraint,\n",
    "                                                                      self.min_common_elements)\n",
    "                            self.cache.user_corrs_in_bulk[time_bin_size][curr_year] = corrs\n",
    "                            curr_year += time_bin_size\n",
    "        else:\n",
    "            raise Exception(\"Trying to create bulk corr cache when use_bulk_corr_cache is False\")\n",
    "\n",
    "    @property\n",
    "    def time_constraint(self):\n",
    "        return self._time_constraint\n",
    "\n",
    "    @time_constraint.setter\n",
    "    def time_constraint(self, value):\n",
    "        self._time_constraint = value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainsetUser:\n",
    "\n",
    "    def __init__(self, cache: Cache):\n",
    "        \"\"\"\n",
    "        :param cache: Input cache must have movie_ratings not None !\n",
    "        \"\"\"\n",
    "        self.cache = cache\n",
    "\n",
    "        if not self.cache.is_movie_ratings_cached:\n",
    "            raise Exception(\"'movie_ratings' has not been cached !\")\n",
    "\n",
    "    def get_users(self):\n",
    "        \"\"\"\n",
    "        Get list of unique 'user_id's\n",
    "\n",
    "        Since MovieLens Have 'user_id's from 0 to 610 without any missing user, for now sending that directly\n",
    "        Uncomment the other lines later\n",
    "\n",
    "        :return: the ids of the users found in movie_ratings\n",
    "        \"\"\"\n",
    "        #\n",
    "        # if self.cache.is_ratings_cached:\n",
    "        #     data = self.cache.ratings\n",
    "        # else:\n",
    "        #     data = self.cache.movie_ratings\n",
    "        #\n",
    "        # return pd.unique(data['user_id'])\n",
    "        return range(0, 611)\n",
    "\n",
    "    def get_active_users(self, n=10) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get Users in sorted order where the first one is the one who has given most ratings.\n",
    "\n",
    "        :param n: Number of users to retrieve.\n",
    "        :return: user DataFrame with index of 'user_id' and columns of ['mean_rating', 'No_of_ratings'] .\n",
    "        \"\"\"\n",
    "\n",
    "        if self.cache.is_ratings_cached:                         # 30% faster than other choice\n",
    "            data = self.cache.ratings\n",
    "        else:\n",
    "            data = self.cache.movie_ratings\n",
    "\n",
    "        active_users = pd.DataFrame(data.groupby('user_id')['rating'].mean())\n",
    "        active_users['No_of_ratings'] = pd.DataFrame(data.groupby('user_id')['rating'].count())\n",
    "        active_users.sort_values(by=['No_of_ratings'], ascending=False, inplace=True)\n",
    "        active_users.columns = ['mean_rating', 'No_of_ratings']\n",
    "        return active_users.head(n)\n",
    "\n",
    "    def get_random_users(self, n=1):\n",
    "        \"\"\"\n",
    "        Get list of random n number of 'user_id's\n",
    "\n",
    "        :param n: Number of random users\n",
    "        :return: List of random 'user_id's\n",
    "        \"\"\"\n",
    "\n",
    "        return random.choices(population=self.get_users(), k=n)\n",
    "\n",
    "    def get_user_ratings(self, user_id: int) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get all the ratings given by of the chosen users\n",
    "\n",
    "        :param user_id: id of the chosen user\n",
    "        :return: Ratings given by the 'user_id'\n",
    "        \"\"\"\n",
    "        if self.cache.is_ratings_cached:                         # 2.2x faster than other choice\n",
    "            data = self.cache.ratings\n",
    "        else:\n",
    "            data = self.cache.movie_ratings\n",
    "\n",
    "        return data.loc[data['user_id'] == user_id]\n",
    "\n",
    "    def get_user_avg(self, user_id: int):\n",
    "\n",
    "        if self.cache.use_avg_ratings_cache:\n",
    "            avg_user_rating = self.cache.avg_user_ratings.loc[user_id]\n",
    "            return avg_user_rating[0] if not avg_user_rating.empty else 0\n",
    "\n",
    "        user_ratings = self.get_user_ratings(user_id=user_id)\n",
    "        return user_ratings.rating.mean() if not user_ratings.empty else 0\n",
    "\n",
    "    def get_timestamp(self, user_id: int, movie_id: int):\n",
    "        \"\"\"\n",
    "        Get the timestamp of the given rating\n",
    "\n",
    "        :param user_id: the users whose rating timestamp we are searching\n",
    "        :param movie_id: id of the movie that the user gave the rating\n",
    "        :return: if found the datetime object otherwise None\n",
    "        \"\"\"\n",
    "\n",
    "        if self.cache.is_ratings_cached:\n",
    "            data = self.cache.ratings\n",
    "        else:\n",
    "            data = self.cache.movie_ratings\n",
    "\n",
    "        timestamp = data.loc[(data['user_id'] == user_id) & (data['item_id'] == movie_id)]\n",
    "        return timestamp.values[0, 3] if not timestamp.empty else None\n",
    "\n",
    "    def get_first_timestamp(self):\n",
    "        if self.cache.is_ratings_cached:\n",
    "            data = self.cache.ratings\n",
    "        else:\n",
    "            data = self.cache.movie_ratings\n",
    "        return data['timestamp'].min()\n",
    "\n",
    "    def get_user_avg_timestamp(self, user_id: int):\n",
    "        user_ratings = self.get_user_ratings(user_id=user_id)\n",
    "        return user_ratings.timestamp.mean() if not user_ratings.empty else 0\n",
    "\n",
    "    # TODO: Later, create TemporalDatasetUser, and put this method into that one\n",
    "    def get_user_ratings_at(self, user_id: int, at: datetime) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get user ratings up until the given datetime\n",
    "        :param user_id: id of the chosen user\n",
    "        :param at: only those ratings that are before this date will be taken into account\n",
    "        :return: Ratings given by the 'user_id' before given datetime\n",
    "        \"\"\"\n",
    "\n",
    "        if self.cache.is_ratings_cached:\n",
    "            data = self.cache.ratings\n",
    "        else:\n",
    "            data = self.cache.movie_ratings\n",
    "\n",
    "        return data.loc[(data['user_id'] == user_id) & (data.timestamp < at)]\n",
    "\n",
    "    # TODO: Later, create TemporalDatasetUser, and put this method into that one\n",
    "    def get_user_avg_at(self, user_id: int, at: datetime):\n",
    "        user_ratings = self.get_user_ratings_at(user_id, at)\n",
    "        return user_ratings.rating.mean() if not user_ratings.empty else 0\n",
    "\n",
    "\n",
    "class TrainsetMovie:\n",
    "\n",
    "    def __init__(self, cache: Cache):\n",
    "        \"\"\"\n",
    "        :param cache: Input cache must have movie_ratings not None !\n",
    "        \"\"\"\n",
    "        self.cache = cache\n",
    "\n",
    "        if not self.cache.is_movie_ratings_cached:\n",
    "            raise Exception(\"'movie_ratings' has not been cached !\")\n",
    "\n",
    "    def get_movie(self, movie_id) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get Movie Record\n",
    "\n",
    "        :return: DataFrame which contains the given 'movie_id's details. If not found empty DataFrame .\n",
    "        \"\"\"\n",
    "        if self.cache.is_movies_cached:\n",
    "            return self.cache.movies.loc[self.cache.movies['item_id'] == movie_id]\n",
    "        return self.cache.movie_ratings.loc[self.cache.movie_ratings['item_id'] == movie_id]\n",
    "\n",
    "    def get_movies(self):\n",
    "        \"\"\"\n",
    "        Get list of unique 'item_id's or in other words the movies.\n",
    "\n",
    "        :return: List of movie ids\n",
    "        \"\"\"\n",
    "\n",
    "        if self.cache.is_movies_cached:\n",
    "            return self.cache.movies['item_id'].values.tolist()\n",
    "\n",
    "        return pd.unique(self.cache.movie_ratings['item_id'])\n",
    "\n",
    "    def get_random_movies(self, n=10):\n",
    "        \"\"\"\n",
    "        Get list of random n number of 'item_id's or in other words the movies\n",
    "\n",
    "        :param n: Number of random movies\n",
    "        :return: List of random 'movie_id's\n",
    "        \"\"\"\n",
    "        return random.choices(population=self.get_movies(), k=n)\n",
    "\n",
    "    def get_movies_watched(self, user_id: int, time_constraint: TimeConstraint = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get all the movies watched by the chosen user.\n",
    "\n",
    "        :param user_id: the user that we want to get the movies he-she has watched.\n",
    "        :param time_constraint: type of the time constraint.\n",
    "        :return: DataFrame of all movies watched with 'item_id', 'rating' columns\n",
    "        \"\"\"\n",
    "\n",
    "        movie_ratings = self.cache.movie_ratings\n",
    "\n",
    "        if time_constraint is None:\n",
    "            return movie_ratings.loc[(movie_ratings['user_id'] == user_id)][['item_id', 'rating']]\n",
    "\n",
    "        if time_constraint.is_valid_max_limit():\n",
    "            return movie_ratings.loc[(movie_ratings['user_id'] == user_id)\n",
    "                                     & (movie_ratings.timestamp < time_constraint.end_dt)][['item_id', 'rating']]\n",
    "        elif time_constraint.is_valid_time_bin():\n",
    "            return movie_ratings.loc[(movie_ratings['user_id'] == user_id)\n",
    "                                     & (movie_ratings.timestamp >= time_constraint.start_dt)\n",
    "                                     & (movie_ratings.timestamp < time_constraint.end_dt)][['item_id', 'rating']]\n",
    "        raise Exception(\"Undefined time_constraint is given!\")\n",
    "\n",
    "    def get_movie_rating(self, movie_id: int, user_id: int) -> int:\n",
    "        \"\"\"\n",
    "        Get the movie rating taken by the chosen user\n",
    "\n",
    "        :param movie_id: the movie chosen movie's id\n",
    "        :param user_id: id of the chosen user\n",
    "        :return: Rating given by user. If not found, returns 0\n",
    "        \"\"\"\n",
    "\n",
    "        if self.cache.is_ratings_cached:\n",
    "            data = self.cache.ratings\n",
    "        else:\n",
    "            data = self.cache.movie_ratings\n",
    "\n",
    "        movie_rating = data.loc[(data['user_id'] == user_id) & (data['item_id'] == movie_id)]\n",
    "        return movie_rating.values[0, 2] if not movie_rating.empty else 0\n",
    "\n",
    "    def get_random_movie_watched(self, user_id: int) -> int:\n",
    "        \"\"\"\n",
    "        Get random movie id watched.\n",
    "\n",
    "        :param user_id: User of interest\n",
    "        :return:  movie_id or item_id of the random movie watched by the user.\n",
    "                  In case non-valid user_id supplied then returns 0\n",
    "        \"\"\"\n",
    "        movies_watched = self.get_movies_watched(user_id=user_id)\n",
    "        return random.choice(movies_watched['item_id'].values.tolist()) if not movies_watched.empty else 0\n",
    "\n",
    "    def get_random_movies_watched(self, user_id: int, n=2) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get random n movies watched by the user. Only use when n > 2\n",
    "\n",
    "        Use get_random_movie_watched if n=1 since that one 2 fold faster.\n",
    "\n",
    "        :param user_id: the user of interest\n",
    "        :param n: number of random movies to get\n",
    "        :return: DataFrame of movies, if none found then empty DataFrame\n",
    "        \"\"\"\n",
    "        movies_watched = self.get_movies_watched(user_id=user_id)\n",
    "        return random.choices(population=movies_watched['item_id'].values.tolist(),\n",
    "                              k=n) if not movies_watched.empty else movies_watched\n",
    "\n",
    "    def get_random_movie_per_user(self, user_id_list):\n",
    "        \"\"\"\n",
    "        Get random movie for each user given in the 'user_id_list'\n",
    "\n",
    "        :param user_id_list: List of valid user_ids\n",
    "        :return: List of (user_id, movie_id) tuples\n",
    "                where each movie_id is randomly chosen from watched movies of the user_id .\n",
    "                In case any one of the user_id's supplies invalid, then the movie_id will be 0 for that user.\n",
    "        \"\"\"\n",
    "        user_movie_list = list()\n",
    "        for user_id in user_id_list:\n",
    "            user_movie_list.append((user_id, self.get_random_movie_watched(user_id=user_id)))\n",
    "        return user_movie_list\n",
    "\n",
    "\n",
    "class Trainset:\n",
    "    def __init__(self, cache: TemporalCache, min_common_elements: int = 5):\n",
    "        self.cache = cache\n",
    "        self.min_common_elements = min_common_elements\n",
    "        self.similarity = TemporalPearson(time_constraint=None, cache=self.cache)\n",
    "\n",
    "        if not self.cache.is_movie_ratings_cached:\n",
    "            raise Exception(\"'movie_ratings' has not been cached !\")\n",
    "\n",
    "        self.trainset_movie = TrainsetMovie(cache=cache)\n",
    "        self.trainset_user = TrainsetUser(cache=cache)\n",
    "\n",
    "        # if caching is allowed, create user correlations cache\n",
    "        self.similarity.get_corr_matrix()\n",
    "\n",
    "    def predict_movies_watched(self, user_id, n=10, k=10, time_constraint=None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "\n",
    "        :param user_id: user of interest\n",
    "        :param n: Number of movies to predict\n",
    "        :param k: k neighbours to take into account\n",
    "        :param time_constraint: When calculating k neighbours,\n",
    "                                only those that comply to time_constraints will be taken into account.\n",
    "        :return: DataFrame of Predictions where columns = ['prediction', 'rating'] index = 'movie_id'\n",
    "        \"\"\"\n",
    "        # Get all movies watched by a user\n",
    "        movies_watched = self.trainset_movie.get_movies_watched(user_id=user_id)\n",
    "\n",
    "        if movies_watched.empty:\n",
    "            return None\n",
    "\n",
    "        predictions = list()\n",
    "        number_of_predictions = 0\n",
    "        for row in movies_watched.itertuples(index=False):\n",
    "            prediction = self.predict_movie(user_id=user_id, movie_id=row[0],\n",
    "                                            time_constraint=time_constraint, k=k)\n",
    "            if number_of_predictions == n:\n",
    "                break\n",
    "            predictions.append([prediction, row[1], row[0]])\n",
    "            number_of_predictions += 1\n",
    "\n",
    "        predictions_df = pd.DataFrame(predictions, columns=['prediction', 'rating', 'movie_id'])\n",
    "        predictions_df.movie_id = predictions_df.movie_id.astype(int)\n",
    "        return predictions_df.set_index('movie_id')\n",
    "\n",
    "    def predict_movie(self, user_id, movie_id, k=10, time_constraint=None, bin_size=-1):\n",
    "        prediction = self.similarity.mean_centered_pearson(user_id=user_id,\n",
    "                                                           movie_id=movie_id,\n",
    "                                                           k_neighbours=\n",
    "                                                           self.get_k_neighbours(user_id, k=k,\n",
    "                                                                                 time_constraint=time_constraint,\n",
    "                                                                                 bin_size=bin_size)\n",
    "                                                           )        \n",
    "        return prediction if prediction <= 5 else 5\n",
    "\n",
    "    def get_k_neighbours(self, user_id, k=20, time_constraint: TimeConstraint = None, bin_size=-1):\n",
    "        \"\"\"\n",
    "        :param user_id: the user of interest\n",
    "        :param k: number of neighbours to retrieve\n",
    "        :param time_constraint: time constraint when choosing neighbours\n",
    "        :param bin_size: Used when using time_bins, in order to select bin from cache\n",
    "        :return: Returns the k neighbours and correlations in between them. If no neighbours found, returns None\n",
    "                 DataFrame which has 'Correlation' column and 'user_id' index.\n",
    "        \"\"\"\n",
    "        self.similarity.time_constraint = time_constraint\n",
    "        user_corr_matrix = self.similarity.get_corr_matrix(bin_size=bin_size)\n",
    "\n",
    "        # Exit if matrix is None, no user found in self.cache.movie_ratings, something is wrong\n",
    "        if user_corr_matrix is None:\n",
    "            return None\n",
    "\n",
    "        # Get the chosen 'user_id's correlations\n",
    "        user_correlations = user_corr_matrix.get(user_id)\n",
    "        if user_correlations is None:\n",
    "            return None\n",
    "\n",
    "        # Drop any null, if found\n",
    "        user_correlations.dropna(inplace=True)\n",
    "        # Create A DataFrame from not-null correlations of the 'user_id'\n",
    "        users_alike = pd.DataFrame(user_correlations)\n",
    "        # Rename the only column to 'correlation'\n",
    "        users_alike.columns = ['correlation']\n",
    "\n",
    "        # Sort the user correlations in descending order\n",
    "        #     so that first one is the most similar, last one least similar\n",
    "        users_alike.sort_values(by='correlation', ascending=False, inplace=True)\n",
    "\n",
    "        # Eliminate Correlation to itself by deleting first row,\n",
    "        #     since biggest corr is with itself it is in first row\n",
    "        return users_alike.iloc[1:k+1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Evaluator:\n",
    "\n",
    "    def __init__(self, trainset: Trainset):\n",
    "        self.trainset = trainset\n",
    "\n",
    "    def evaluate_best_max_year_in_bulk(self, n,\n",
    "                                       n_users, n_movies, k=10,\n",
    "                                       min_year=-1,\n",
    "                                       max_year=-1) -> dict:\n",
    "        \"\"\"\n",
    "        Evaluate and collect data about best max year constraint which can be put instead of no constraint.\n",
    "\n",
    "        This method calls 'evaluate_best_max_year_constraint' method 'n' times.\n",
    "        Takes required precautions for bulk calling.\n",
    "\n",
    "        :param n: Number of runs that we run the evaluate_best_max_year_constraint() method\n",
    "        :param n_users: Number of users to check\n",
    "        :param n_movies: Number of movies per user to check\n",
    "        :param k: Number of neighbours of each user to take into account when making prediction\n",
    "        :param min_year: First year to evaluate\n",
    "        :param max_year: Last year to evaluate\n",
    "        :return: (no_constrain_rmse_data, best_year_constraint_results)\n",
    "        \"\"\"\n",
    "        if min_year == -1:\n",
    "            min_year = self.trainset.trainset_user.get_first_timestamp().year\n",
    "\n",
    "        if max_year == -1:\n",
    "            max_year = datetime.now().year\n",
    "\n",
    "        time_constraint = TimeConstraint(end_dt=datetime(year=min_year, month=1, day=1))\n",
    "        # Create cache if bulk_corr_cache is allowed\n",
    "        self.trainset.similarity.cache_user_corrs_in_bulk_for_max_limit(time_constraint,\n",
    "                                                                        min_year=min_year,\n",
    "                                                                        max_year=max_year)\n",
    "        \n",
    "        run_results = dict()\n",
    "        for i in range(n):\n",
    "            run_results[i] = self.evaluate_best_max_year_constraint(n_users=n_users, n_movies=n_movies, k=k,\n",
    "                                                                    min_year=min_year, max_year=max_year,\n",
    "                                                                    create_cache=False,)\n",
    "\n",
    "        return run_results\n",
    "\n",
    "    def evaluate_best_max_year_constraint(self, n_users, n_movies, k,\n",
    "                                          max_diff=0.1,\n",
    "                                          min_year=-1, max_year=-1,\n",
    "                                          create_cache=True) -> defaultdict:\n",
    "        \"\"\"\n",
    "        Evaluate the max_year constraint for evaluate_max_year_constraint method.\n",
    "\n",
    "        :param max_diff: maximum difference between rmse when no constraint and with given year constraint.\n",
    "        :param n_users: Number of users to evaluate\n",
    "        :param n_movies: Number of movies per user to evaluate\n",
    "        :param k: Number of neighbours of each user to take into account when making prediction\n",
    "        :param min_year: First year to evaluate\n",
    "        :param max_year: Last year to evaluate\n",
    "        :param create_cache: create cache before running. For bulk callers.\n",
    "        :return: Votes for years where each year got its vote\n",
    "                 when rmse is less than 'max_diff' in between no constraint and year constraint\n",
    "        \"\"\"\n",
    "\n",
    "        if min_year == -1:\n",
    "            min_year = self.trainset.trainset_user.get_first_timestamp().year\n",
    "\n",
    "        if max_year == -1:\n",
    "            max_year = datetime.now().year\n",
    "\n",
    "        if n_users > 600:\n",
    "            user_list = self.trainset.trainset_user.get_users()  # No need to random selection, get all users\n",
    "        else:\n",
    "            user_list = self.trainset.trainset_user.get_random_users(n=n_users)  # Select random n users\n",
    "\n",
    "        # Calculate RMSE With No Constraint\n",
    "        no_constraint_data = dict()\n",
    "        for user_id in user_list:\n",
    "            rmse = Accuracy.rmse(self.trainset.predict_movies_watched(user_id, n_movies, k))\n",
    "            no_constraint_data[user_id] = rmse\n",
    "\n",
    "        # # Calculate RMSE With Time Constraint\n",
    "\n",
    "        # Cache all years before processing\n",
    "        time_constraint = TimeConstraint(end_dt=datetime(year=min_year, month=1, day=1))\n",
    "        # Create cache if bulk_corr_cache is allowed\n",
    "        if create_cache:\n",
    "            self.trainset.similarity.cache_user_corrs_in_bulk_for_max_limit(time_constraint,\n",
    "                                                                            min_year=min_year,\n",
    "                                                                            max_year=max_year)\n",
    "        # Votes to years is stored inside time_constraint_data\n",
    "        time_constraint_data = defaultdict(int)\n",
    "        for year in range(min_year, max_year):\n",
    "            time_constraint.end_dt = time_constraint.end_dt.replace(year=year)\n",
    "\n",
    "            for user_id in user_list:\n",
    "                rmse = Accuracy.rmse(self.trainset.predict_movies_watched(user_id=user_id, n=n_movies, k=k,\n",
    "                                                                          time_constraint=time_constraint))\n",
    "                if abs(rmse - no_constraint_data[user_id]) < max_diff:\n",
    "                    time_constraint_data[year] += 1\n",
    "\n",
    "        return time_constraint_data\n",
    "\n",
    "    def evaluate_max_year_constraint(self, n_users, n_movies, k, time_constraint):\n",
    "        \"\"\"\n",
    "        Compare given time_constraint with normal where no constraint exists.\n",
    "\n",
    "        Time constraint is of type max_year which means the system will be set to a certain year.\n",
    "\n",
    "        :param n_users: Number of users to evaluate\n",
    "        :param n_movies: Number of movies per user to evaluate\n",
    "        :param k: Number of neighbours to take into account when making movie prediction\n",
    "        :param time_constraint: Time constraint which will be applied.\n",
    "        :return: DataFrame of results which contains rmse with constraint and no constraint, as well as runtime.\n",
    "        \"\"\"\n",
    "        trainset = self.trainset\n",
    "        data = list()\n",
    "\n",
    "        for i in range(n_users):\n",
    "            # Get Random User\n",
    "            user_id = random.randint(1, 610)\n",
    "            # Predict movies for user and record runtime\n",
    "            st = default_timer()\n",
    "            rmse = Accuracy.rmse(\n",
    "                trainset.predict_movies_watched(user_id=user_id, n=n_movies, k=k, time_constraint=None))\n",
    "            r1 = default_timer() - st\n",
    "            # Predict movies with time_constraint for user and record runtime\n",
    "            st = default_timer()\n",
    "            time_constrained_rmse = Accuracy.rmse(\n",
    "                trainset.predict_movies_watched(user_id=user_id, n=n_movies, k=k, time_constraint=time_constraint))\n",
    "            r2 = default_timer() - st\n",
    "            # Save iteration data\n",
    "            data.append([user_id, rmse, r1, time_constrained_rmse, r2])\n",
    "\n",
    "        data = pd.DataFrame(data)\n",
    "        data.columns = ['user_id', 'rmse', 'runtime1', 'temporal_rmse', 'runtime2']\n",
    "        data.set_index('user_id', inplace=True)\n",
    "        return data\n",
    "\n",
    "    def evaluate_time_bins_in_bulk(self, n, n_users, k=10,\n",
    "                                   min_year=-1,\n",
    "                                   max_year=-1,\n",
    "                                   min_time_bin_size=2, max_time_bin_size=10):\n",
    "        \"\"\"\n",
    "        Evaluate time bins and return the results.\n",
    "\n",
    "        This method calls 'evaluate_time_bins' method 'n' times. Takes required precautions for bulk calling.\n",
    "\n",
    "        :param n: Number of runs\n",
    "        :param n_users: Number of users\n",
    "        :param k: Number of neighbours will be used when making prediction\n",
    "        :param min_year: First year to start when taking time bins\n",
    "        :param max_year: When to stop when taking time bins, last is not included.\n",
    "        :param min_time_bin_size: Minimum bin size in years\n",
    "        :param max_time_bin_size: Maximum bin size in years\n",
    "        :return: Evaluation results\n",
    "        \"\"\"\n",
    "        if min_year == -1:\n",
    "            min_year = self.trainset.trainset_user.get_first_timestamp().year\n",
    "\n",
    "        if max_year == -1:\n",
    "            max_year = datetime.now().year\n",
    "\n",
    "        # Cache all years before processing\n",
    "        time_constraint = TimeConstraint(start_dt=datetime(year=min_year, month=1, day=1),\n",
    "                                         end_dt=datetime(year=max_year, month=1, day=1))\n",
    "        self.trainset.similarity.cache_user_corrs_in_bulk_for_time_bins(time_constraint,\n",
    "                                                                        min_year=min_year,\n",
    "                                                                        max_year=max_year,\n",
    "                                                                        min_time_bin_size=min_time_bin_size,\n",
    "                                                                        max_time_bin_size=max_time_bin_size)\n",
    "\n",
    "        run_results = dict()\n",
    "        for i in range(n):\n",
    "            run_results[i] = self.evaluate_time_bins(n_users=n_users, k=k, min_year=min_year, max_year=max_year,\n",
    "                                                     min_time_bin_size=min_time_bin_size,\n",
    "                                                     max_time_bin_size=max_time_bin_size,\n",
    "                                                     create_cache=False)\n",
    "\n",
    "        return run_results\n",
    "\n",
    "    def evaluate_time_bins(self, n_users, k, min_year=-1, max_year=-1,\n",
    "                           min_time_bin_size=2, max_time_bin_size=10,\n",
    "                           create_cache=True) -> dict:\n",
    "        \"\"\"\n",
    "\n",
    "        :param n_users: Number of users\n",
    "        :param k: Number of neighbours will be used when making prediction\n",
    "        :param min_year: First year to start when taking time bins\n",
    "        :param max_year: When to stop when taking time bins, last is not included.\n",
    "        :param min_time_bin_size: Minimum bin size in years\n",
    "        :param max_time_bin_size: Maximum bin size in years\n",
    "        :param create_cache: Create cache before calling time bins. For bulk callers.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        trainset = self.trainset\n",
    "\n",
    "        if min_year == -1:\n",
    "            min_year = self.trainset.trainset_user.get_first_timestamp().year\n",
    "\n",
    "        if max_year == -1:\n",
    "            max_year = datetime.now().year\n",
    "\n",
    "        if n_users > 600:\n",
    "            user_list = trainset.trainset_user.get_users()\n",
    "        else:\n",
    "            user_list = trainset.trainset_user.get_random_users(n=n_users)\n",
    "        user_movie_list = trainset.trainset_movie.get_random_movie_per_user(user_list)\n",
    "        data = dict()\n",
    "\n",
    "        result = list()\n",
    "\n",
    "        if create_cache:\n",
    "            # Cache all years before processing\n",
    "            time_constraint = TimeConstraint(start_dt=datetime(year=min_year, month=1, day=1),\n",
    "                                             end_dt=datetime(year=max_year, month=1, day=1))\n",
    "            self.trainset.similarity.cache_user_corrs_in_bulk_for_time_bins(time_constraint,\n",
    "                                                                            min_year=min_year,\n",
    "                                                                            max_year=max_year,\n",
    "                                                                            min_time_bin_size=min_time_bin_size,\n",
    "                                                                            max_time_bin_size=max_time_bin_size)\n",
    "\n",
    "        # Take each bins where first bin 'min_time_bin_size' years, last one 'max_time_bin_size - 1' years\n",
    "        for time_bin_size in range(min_time_bin_size, max_time_bin_size):\n",
    "            # Shift each time_bin starting with 0 years up until (time_bin-1) years\n",
    "            for shift in range(0, time_bin_size):\n",
    "                curr_year = min_year + shift\n",
    "                predictions = list()\n",
    "                start_time = default_timer()\n",
    "                # Scan and make predictions for all the time_bins\n",
    "                while (curr_year + time_bin_size) < max_year:\n",
    "                    for user_id, movie_id in user_movie_list:\n",
    "                        p = trainset.predict_movie(user_id=user_id, movie_id=movie_id, k=k,\n",
    "                                                   time_constraint=TimeConstraint(start_dt=datetime(curr_year, 1, 1),\n",
    "                                                                                  end_dt=datetime(curr_year+time_bin_size, 1, 1)),\n",
    "                                                   bin_size=time_bin_size)\n",
    "                        # if prediction has been done successfully\n",
    "                        if p != 0:\n",
    "                            r = trainset.trainset_movie.get_movie_rating(movie_id=movie_id, user_id=user_id)\n",
    "                            # Append (prediction, actual_rating)\n",
    "                            predictions.append((p, r))\n",
    "                    curr_year += time_bin_size\n",
    "                runtime = default_timer() - start_time\n",
    "                bin_rmse = Accuracy.rmse(predictions=predictions)\n",
    "                iteration_results = {\"bin_size\": time_bin_size,\n",
    "                                     \"start_year\": min_year + shift,\n",
    "                                     \"predictions\": predictions,\n",
    "                                     \"rmse\": bin_rmse,\n",
    "                                     \"runtime\": runtime\n",
    "                                     }\n",
    "                result.append(iteration_results)\n",
    "\n",
    "        data['result'] = result\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = TemporalCache(time_constraint=None, \n",
    "                  is_ratings_cached=True,\n",
    "                  is_movies_cached=True,\n",
    "                  is_movie_ratings_cached=True,\n",
    "                  ratings=MovieLensDataset.load_ratings(r'C:\\Users\\Yukawa\\datasets\\ml-latest-small\\ratings.csv'),\n",
    "                  movies=MovieLensDataset.load_movies(r'C:\\Users\\Yukawa\\datasets\\ml-latest-small\\movies.csv'),\n",
    "                  movie_ratings=MovieLensDataset.load(),\n",
    "                  is_user_correlations_cached=True,\n",
    "                  use_bulk_corr_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Trainset(cache=c, min_common_elements=5)\n",
    "e = Evaluator(trainset=t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timebin Based Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MovieLensDataset(is_movies_cached=True, is_ratings_cached=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_timebin_corr(ratings, timebin, avg_rating, user_id, timebin_time_constraint):\n",
    "    curr_bin = t.trainset_movie.get_movies_watched(user_id, timebin_time_constraint)\n",
    "    merged = curr_bin.merge(timebin, on='item_id')\n",
    "    common_elements = len(merged)\n",
    "    \n",
    "    t.trainset_user.get_user_avg_at(user_id,)\n",
    "    user_avg_rating = t.trainset_user.get_user_avg(user_id)\n",
    "    numenator = ((merged['rating_x'] - avg_rating) * (merged['rating_y'] - user_avg_rating)).sum()\n",
    "    denominator = math.sqrt(((merged['rating_x'] - avg_rating) ** 2).sum())\n",
    "    denominator *= math.sqrt(((merged['rating_y'] - user_avg_rating) ** 2).sum())\n",
    "    pearson = numenator / denominator\n",
    "    \n",
    "    return pearson, common_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_movies_watched_from_timebin(timebin, user_id: int, n=2) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get random n movies watched by the user. \n",
    "    \"\"\"\n",
    "    return sample(timebin.index.to_list(),n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timebin_size(tc: TimeConstraint):\n",
    "    return abs((tc.start_dt - tc.end_dt).days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movies_watched(ratings, user_id: int, time_constraint: TimeConstraint = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get all the movies watched by the chosen user.\n",
    "\n",
    "    :param user_id: the user that we want to get the movies he-she has watched.\n",
    "    :param time_constraint: type of the time constraint.\n",
    "    :return: DataFrame of all movies watched with 'item_id', 'rating' columns\n",
    "    \"\"\"\n",
    "\n",
    "    movie_ratings = ratings\n",
    "    \n",
    "    if time_constraint is None:\n",
    "        return movie_ratings.loc[(movie_ratings['user_id'] == user_id)][['item_id', 'rating', 'timestamp']].set_index('item_id')\n",
    "\n",
    "    if time_constraint.is_valid_max_limit():\n",
    "        return movie_ratings.loc[(movie_ratings['user_id'] == user_id)\n",
    "                                 & (movie_ratings.timestamp < time_constraint.end_dt)][['item_id', 'rating', 'timestamp']].set_index('item_id')\n",
    "    elif time_constraint.is_valid_time_bin():\n",
    "        return movie_ratings.loc[(movie_ratings['user_id'] == user_id)\n",
    "                                 & (movie_ratings.timestamp >= time_constraint.start_dt)\n",
    "                                 & (movie_ratings.timestamp < time_constraint.end_dt)][['item_id', 'rating', 'timestamp']].set_index('item_id')\n",
    "    raise Exception(\"Undefined time_constraint is given!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timebin(ratings, user_id: int, time_constraint) -> pd.DataFrame:\n",
    "    return get_movies_watched(ratings, user_id=user_id, time_constraint=time_constraint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timebin_neighbours(ratings, user_id, time_constraint, k:int):\n",
    "    # Get the user timebin\n",
    "    timebin = get_timebin(ratings, user_id, time_constraint)\n",
    "    \n",
    "    # Count number of common ratings with other users\n",
    "    userlist = [0 for i in range(611)]\n",
    "    for movie_id in timebin.index.values.tolist():\n",
    "        users_who_watched = ratings.loc[(ratings['item_id'] == 3) & (ratings['timestamp'] < time_constraint.end_dt)][['user_id']].values.tolist()\n",
    "        for user_who_watched in users_who_watched:\n",
    "            userlist[user_who_watched[0]] += 1\n",
    "    \n",
    "    # Filter k of them\n",
    "    neighbour_id_list = []\n",
    "    for i in range(0, 611):\n",
    "        if userlist[i] > k:\n",
    "            neighbour_id_list.append(i)\n",
    "    return neighbour_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 6,\n",
       " 19,\n",
       " 32,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 51,\n",
       " 58,\n",
       " 64,\n",
       " 68,\n",
       " 91,\n",
       " 100,\n",
       " 102,\n",
       " 116,\n",
       " 117,\n",
       " 150,\n",
       " 151,\n",
       " 169,\n",
       " 179,\n",
       " 217,\n",
       " 226,\n",
       " 240,\n",
       " 269,\n",
       " 270,\n",
       " 288,\n",
       " 289,\n",
       " 294,\n",
       " 302,\n",
       " 307,\n",
       " 308,\n",
       " 321,\n",
       " 330,\n",
       " 337,\n",
       " 368,\n",
       " 410,\n",
       " 414,\n",
       " 448,\n",
       " 456,\n",
       " 470,\n",
       " 477,\n",
       " 480,\n",
       " 492,\n",
       " 501,\n",
       " 544,\n",
       " 552,\n",
       " 555,\n",
       " 588,\n",
       " 590,\n",
       " 594,\n",
       " 599,\n",
       " 608]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_timebin_neighbours(dataset.ratings, 443, TimeConstraint(start_dt=datetime(year=2017, month=1, day=1), end_dt=datetime.now()), k = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prevalent_genre(timebin):\n",
    "    genre_voting = defaultdict(int)\n",
    "    for row in timebin.itertuples(index=False):\n",
    "        genres = row[4]\n",
    "        for genre in genres.split(\"|\"): \n",
    "            genre_voting[genre] += 1\n",
    "    return max(genre_voting.items(), key=lambda a: a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timebin_length(movies, timebin) -> timedelta:\n",
    "    timebin = pd.merge(timebin, movies, left_index=True, right_on='item_id')\n",
    "    genre = get_prevalent_genre(timebin)   # like ('action', 10)\n",
    "    first_item_ts = timebin.iloc[-1][1]\n",
    "    last_item_ts = None\n",
    "    for i in range(len(timebin)):\n",
    "        if 'Action' in timebin.iloc[-i][4].split(\"|\"):\n",
    "            last_item_ts = timebin.iloc[-i][1]\n",
    "    return first_item_ts - last_item_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_similar_timebins(ratings, movies, user_id, time_constraint, k, n, corr_treshold):\n",
    "    \"\"\"\n",
    "    k: Komşunun genel ortak film sayısı\n",
    "    n: timebin içindeki ortak film sayısı\n",
    "    \"\"\"\n",
    "    # Get the user timebin\n",
    "    timebin = get_timebin(ratings, user_id, time_constraint)\n",
    "    \n",
    "    # Get timebin length using most prevalent genre\n",
    "    timebin_length = int(get_timebin_length(movies, timebin).total_seconds())\n",
    "    \n",
    "    if timebin_length < 86_400_000:\n",
    "        timebin_length *= 10_000\n",
    "    \n",
    "    # Define limits\n",
    "    first_timestamp = ratings['timestamp'].min()\n",
    "    max_timebin_length = int(abs(first_timestamp - time_constraint.end_dt).total_seconds())\n",
    "    \n",
    "    # Neighbours contains users who has watched the movies in common\n",
    "    neighbours = get_timebin_neighbours(ratings, user_id, time_constraint, k)\n",
    "    \n",
    "    # Avg rating of the user\n",
    "    avg_rating = t.trainset_user.get_user_avg(user_id)\n",
    "    \n",
    "    data = list()\n",
    "    start_time = default_timer()\n",
    "    for timebin_size in range(timebin_length, max_timebin_length, timebin_length):\n",
    "        for shift in range(0, timebin_size, timebin_size//10):    # make 10 start time shift\n",
    "            start_dt = first_timestamp + timedelta(seconds=shift)    # assign start time \n",
    "            curr_dt = start_dt\n",
    "            while (curr_dt + timedelta(seconds=timebin_length)) < time_constraint.end_dt:\n",
    "                for user_id in neighbours:   \n",
    "                    end_dt = curr_dt + timedelta(days=timebin_length)\n",
    "                    # find curr_timebin\n",
    "                    timebin_time_constraint = TimeConstraint(start_dt=curr_dt, end_dt=end_dt)\n",
    "                    corr, common_elements = find_timebin_corr(ratings, timebin=timebin, avg_rating=avg_rating, \n",
    "                                             user_id=user_id, timebin_time_constraint=timebin_time_constraint)\n",
    "                    # if and only if more than n movies in common rated in the temporal time bin, get the correlations\n",
    "                    if not math.isnan(corr) and common_elements > n and corr > corr_treshold:\n",
    "                        data.append( (user_id, curr_dt, timebin_size, corr) )\n",
    "                        print( (user_id, curr_dt, timebin_size, corr) )\n",
    "                        \n",
    "                curr_dt = end_dt                        #curr_dt + timedelta(days=timebin_size)\n",
    "                #print(f\"start={start_dt} -  curr={curr_dt}, shift={shift}, timebin_size ={timebin_size}\")\n",
    "    runtime = default_timer() - start_time\n",
    "    print(f\"runtime={runtime}\")    \n",
    "    return pd.DataFrame(data, columns=['user_id', 'start_dt', 'bin_size_in_days', 'pearson_corr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OverflowError",
     "evalue": "int too big to convert",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-7012d4647aea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m df = get_most_similar_timebins(dataset.ratings,dataset.movies, 443,\n\u001b[1;32m----> 2\u001b[1;33m                                TimeConstraint(start_dt=datetime(year=2017, month=1, day=1), end_dt=datetime.now()), 5, 3, 0.5)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-83-6b4bd02afb03>\u001b[0m in \u001b[0;36mget_most_similar_timebins\u001b[1;34m(ratings, movies, user_id, time_constraint, k, n, corr_treshold)\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcurr_dt\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseconds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimebin_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mtime_constraint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend_dt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0muser_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mneighbours\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m                     \u001b[0mend_dt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcurr_dt\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimebin_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m                     \u001b[1;31m# find curr_timebin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m                     \u001b[0mtimebin_time_constraint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTimeConstraint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_dt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_dt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_dt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mend_dt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\tslibs\\c_timestamp.pyx\u001b[0m in \u001b[0;36mpandas._libs.tslibs.c_timestamp._Timestamp.__add__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOverflowError\u001b[0m: int too big to convert"
     ]
    }
   ],
   "source": [
    "df = get_most_similar_timebins(dataset.ratings,dataset.movies, 443,\n",
    "                               TimeConstraint(start_dt=datetime(year=2017, month=1, day=1), end_dt=datetime.now()), 5, 3, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(['bin_size_in_days', 'pearson_corr'], ascending=[True, False], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>start_dt</th>\n",
       "      <th>bin_size_in_days</th>\n",
       "      <th>pearson_corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>414</td>\n",
       "      <td>1999-08-25 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.943269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>414</td>\n",
       "      <td>1999-12-27 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.943269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>414</td>\n",
       "      <td>2000-04-29 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.943269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>414</td>\n",
       "      <td>1999-08-21 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.943269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>414</td>\n",
       "      <td>1997-04-05 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.935812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>217</td>\n",
       "      <td>1996-03-29 18:36:55</td>\n",
       "      <td>8708</td>\n",
       "      <td>-0.514511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>308</td>\n",
       "      <td>1996-03-29 18:36:55</td>\n",
       "      <td>8708</td>\n",
       "      <td>-0.532620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>91</td>\n",
       "      <td>1996-03-29 18:36:55</td>\n",
       "      <td>8708</td>\n",
       "      <td>-0.552446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>68</td>\n",
       "      <td>1996-03-29 18:36:55</td>\n",
       "      <td>8708</td>\n",
       "      <td>-0.597608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>307</td>\n",
       "      <td>1996-03-29 18:36:55</td>\n",
       "      <td>8708</td>\n",
       "      <td>-0.677503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>966 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id            start_dt  bin_size_in_days  pearson_corr\n",
       "16       414 1999-08-25 18:36:55              1244      0.943269\n",
       "48       414 1999-12-27 18:36:55              1244      0.943269\n",
       "71       414 2000-04-29 18:36:55              1244      0.943269\n",
       "242      414 1999-08-21 18:36:55              1244      0.943269\n",
       "88       414 1997-04-05 18:36:55              1244      0.935812\n",
       "..       ...                 ...               ...           ...\n",
       "946      217 1996-03-29 18:36:55              8708     -0.514511\n",
       "953      308 1996-03-29 18:36:55              8708     -0.532620\n",
       "942       91 1996-03-29 18:36:55              8708     -0.552446\n",
       "941       68 1996-03-29 18:36:55              8708     -0.597608\n",
       "952      307 1996-03-29 18:36:55              8708     -0.677503\n",
       "\n",
       "[966 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>start_dt</th>\n",
       "      <th>bin_size_in_days</th>\n",
       "      <th>pearson_corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>414</td>\n",
       "      <td>1999-08-25 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.943269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>414</td>\n",
       "      <td>1999-12-27 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.943269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>414</td>\n",
       "      <td>2000-04-29 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.943269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>414</td>\n",
       "      <td>1999-08-21 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.943269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>414</td>\n",
       "      <td>1997-04-05 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.935812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>414</td>\n",
       "      <td>1997-08-07 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.935812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>414</td>\n",
       "      <td>1997-12-09 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.935812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>414</td>\n",
       "      <td>1998-04-12 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.935812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>414</td>\n",
       "      <td>1998-08-14 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.935812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>414</td>\n",
       "      <td>1998-12-16 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.935812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>414</td>\n",
       "      <td>1999-04-19 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.935812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>169</td>\n",
       "      <td>2003-01-20 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.929164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>169</td>\n",
       "      <td>2003-05-24 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.929164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>169</td>\n",
       "      <td>2001-01-02 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.929164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>169</td>\n",
       "      <td>2001-05-06 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.929164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>169</td>\n",
       "      <td>2001-09-07 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.929164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>169</td>\n",
       "      <td>2002-01-09 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.929164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>169</td>\n",
       "      <td>2002-05-13 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.929164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>169</td>\n",
       "      <td>2002-09-14 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.929164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>169</td>\n",
       "      <td>2003-01-16 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.929164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>555</td>\n",
       "      <td>1999-08-25 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.922836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>555</td>\n",
       "      <td>1999-12-27 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.922836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>555</td>\n",
       "      <td>2000-04-29 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.922836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>555</td>\n",
       "      <td>2000-08-31 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.922836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>555</td>\n",
       "      <td>2001-01-02 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.922836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id            start_dt  bin_size_in_days  pearson_corr\n",
       "16       414 1999-08-25 18:36:55              1244      0.943269\n",
       "48       414 1999-12-27 18:36:55              1244      0.943269\n",
       "71       414 2000-04-29 18:36:55              1244      0.943269\n",
       "242      414 1999-08-21 18:36:55              1244      0.943269\n",
       "88       414 1997-04-05 18:36:55              1244      0.935812\n",
       "111      414 1997-08-07 18:36:55              1244      0.935812\n",
       "133      414 1997-12-09 18:36:55              1244      0.935812\n",
       "156      414 1998-04-12 18:36:55              1244      0.935812\n",
       "178      414 1998-08-14 18:36:55              1244      0.935812\n",
       "200      414 1998-12-16 18:36:55              1244      0.935812\n",
       "221      414 1999-04-19 18:36:55              1244      0.935812\n",
       "20       169 2003-01-20 18:36:55              1244      0.929164\n",
       "53       169 2003-05-24 18:36:55              1244      0.929164\n",
       "113      169 2001-01-02 18:36:55              1244      0.929164\n",
       "136      169 2001-05-06 18:36:55              1244      0.929164\n",
       "158      169 2001-09-07 18:36:55              1244      0.929164\n",
       "181      169 2002-01-09 18:36:55              1244      0.929164\n",
       "203      169 2002-05-13 18:36:55              1244      0.929164\n",
       "224      169 2002-09-14 18:36:55              1244      0.929164\n",
       "246      169 2003-01-16 18:36:55              1244      0.929164\n",
       "18       555 1999-08-25 18:36:55              1244      0.922836\n",
       "50       555 1999-12-27 18:36:55              1244      0.922836\n",
       "73       555 2000-04-29 18:36:55              1244      0.922836\n",
       "93       555 2000-08-31 18:36:55              1244      0.922836\n",
       "115      555 2001-01-02 18:36:55              1244      0.922836"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_dt</th>\n",
       "      <th>bin_size_in_days</th>\n",
       "      <th>pearson_corr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1999-08-25 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.943269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1997-08-08 18:36:55</td>\n",
       "      <td>4976</td>\n",
       "      <td>0.929164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>1999-08-21 18:36:55</td>\n",
       "      <td>2488</td>\n",
       "      <td>0.922836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1996-03-29 18:36:55</td>\n",
       "      <td>2488</td>\n",
       "      <td>0.830366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>1998-12-16 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.788232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1996-03-29 18:36:55</td>\n",
       "      <td>6220</td>\n",
       "      <td>0.757158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>2009-11-08 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.698530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>2006-06-13 18:36:55</td>\n",
       "      <td>2488</td>\n",
       "      <td>0.666486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1996-03-29 18:36:55</td>\n",
       "      <td>3732</td>\n",
       "      <td>0.665170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>2000-04-29 18:36:55</td>\n",
       "      <td>3732</td>\n",
       "      <td>0.642239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>1998-04-12 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.583354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1996-03-29 18:36:55</td>\n",
       "      <td>7464</td>\n",
       "      <td>0.567006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1998-04-12 18:36:55</td>\n",
       "      <td>2488</td>\n",
       "      <td>0.489127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>1998-04-14 18:36:55</td>\n",
       "      <td>7464</td>\n",
       "      <td>0.484322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>1996-07-31 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.479119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2003-09-25 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.428254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997-12-09 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.314515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>2002-05-15 18:36:55</td>\n",
       "      <td>3732</td>\n",
       "      <td>0.286113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>1996-03-29 18:36:55</td>\n",
       "      <td>2488</td>\n",
       "      <td>0.245177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1996-03-29 18:36:55</td>\n",
       "      <td>2488</td>\n",
       "      <td>0.094906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>1996-03-29 18:36:55</td>\n",
       "      <td>3732</td>\n",
       "      <td>0.062453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>1997-12-09 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.042771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>1996-03-29 18:36:55</td>\n",
       "      <td>8708</td>\n",
       "      <td>0.015333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>1996-03-29 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>-0.039277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>2008-06-30 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>-0.296567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>2001-05-08 18:36:55</td>\n",
       "      <td>6220</td>\n",
       "      <td>-0.323415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>1996-03-29 18:36:55</td>\n",
       "      <td>8708</td>\n",
       "      <td>-0.347745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>1997-12-09 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>-0.514511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>2005-06-07 18:36:55</td>\n",
       "      <td>3732</td>\n",
       "      <td>-0.532620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2005-02-02 18:36:55</td>\n",
       "      <td>1244</td>\n",
       "      <td>-0.552446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2003-01-12 18:36:55</td>\n",
       "      <td>2488</td>\n",
       "      <td>-0.564306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>1998-04-14 18:36:55</td>\n",
       "      <td>7464</td>\n",
       "      <td>-0.677503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   start_dt  bin_size_in_days  pearson_corr\n",
       "user_id                                                    \n",
       "414     1999-08-25 18:36:55              1244      0.943269\n",
       "169     1997-08-08 18:36:55              4976      0.929164\n",
       "555     1999-08-21 18:36:55              2488      0.922836\n",
       "32      1996-03-29 18:36:55              2488      0.830366\n",
       "288     1998-12-16 18:36:55              1244      0.788232\n",
       "179     1996-03-29 18:36:55              6220      0.757158\n",
       "590     2009-11-08 18:36:55              1244      0.698530\n",
       "480     2006-06-13 18:36:55              2488      0.666486\n",
       "43      1996-03-29 18:36:55              3732      0.665170\n",
       "477     2000-04-29 18:36:55              3732      0.642239\n",
       "294     1998-04-12 18:36:55              1244      0.583354\n",
       "58      1996-03-29 18:36:55              7464      0.567006\n",
       "42      1998-04-12 18:36:55              2488      0.489127\n",
       "226     1998-04-14 18:36:55              7464      0.484322\n",
       "302     1996-07-31 18:36:55              1244      0.479119\n",
       "64      2003-09-25 18:36:55              1244      0.428254\n",
       "1       1997-12-09 18:36:55              1244      0.314515\n",
       "448     2002-05-15 18:36:55              3732      0.286113\n",
       "588     1996-03-29 18:36:55              2488      0.245177\n",
       "6       1996-03-29 18:36:55              2488      0.094906\n",
       "117     1996-03-29 18:36:55              3732      0.062453\n",
       "368     1997-12-09 18:36:55              1244      0.042771\n",
       "240     1996-03-29 18:36:55              8708      0.015333\n",
       "470     1996-03-29 18:36:55              1244     -0.039277\n",
       "330     2008-06-30 18:36:55              1244     -0.296567\n",
       "608     2001-05-08 18:36:55              6220     -0.323415\n",
       "599     1996-03-29 18:36:55              8708     -0.347745\n",
       "217     1997-12-09 18:36:55              1244     -0.514511\n",
       "308     2005-06-07 18:36:55              3732     -0.532620\n",
       "91      2005-02-02 18:36:55              1244     -0.552446\n",
       "68      2003-01-12 18:36:55              2488     -0.564306\n",
       "307     1998-04-14 18:36:55              7464     -0.677503"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='pearson_corr', ascending=False).drop_duplicates('user_id').set_index('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-08-03 01:08:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2017-08-03 01:07:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-08-03 01:07:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-08-03 01:07:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-08-03 01:07:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-08-03 01:07:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-08-03 01:08:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5952</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-08-03 01:08:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7153</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-08-03 01:08:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79132</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2017-08-03 01:11:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96430</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-08-03 01:09:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106918</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-08-03 01:09:46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating           timestamp\n",
       "item_id                            \n",
       "1           4.0 2017-08-03 01:08:02\n",
       "110         4.5 2017-08-03 01:07:57\n",
       "260         4.0 2017-08-03 01:07:45\n",
       "296         4.0 2017-08-03 01:07:47\n",
       "318         5.0 2017-08-03 01:07:38\n",
       "356         5.0 2017-08-03 01:07:41\n",
       "608         5.0 2017-08-03 01:08:15\n",
       "5952        5.0 2017-08-03 01:08:17\n",
       "7153        5.0 2017-08-03 01:08:18\n",
       "79132       1.0 2017-08-03 01:11:35\n",
       "96430       5.0 2017-08-03 01:09:03\n",
       "106918      5.0 2017-08-03 01:09:46"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc = TimeConstraint(start_dt=datetime(year=2017, month=1, day=1), end_dt=datetime.now())\n",
    "tb = get_timebin(dataset.ratings, user_id=443, time_constraint=tc)\n",
    "tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_movies_watched(timebin, user_id, timeconstraint):\n",
    "    movies_watched = timebin.index.to_list()\n",
    "    predictions = list()\n",
    "    for movie in movies_watched:\n",
    "        prediction = t.predict_movie(user_id=user_id, movie_id=movie, k=10)\n",
    "        if prediction != 0:\n",
    "            actual = t.trainset_movie.get_movie_rating(movie_id=movie, user_id=user_id)\n",
    "            predictions.append((prediction, actual))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4.121621621621622, 4.5),\n",
       " (3.5412895265381175, 4.0),\n",
       " (3.9815086592962965, 4.0),\n",
       " (4.726583392125758, 5.0),\n",
       " (4.511206121155887, 5.0),\n",
       " (5, 5.0),\n",
       " (4.900062273990611, 5.0),\n",
       " (4.900062273990611, 5.0),\n",
       " (3.939462223865436, 1.0),\n",
       " (4.042003787226717, 5.0)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = predict_movies_watched(timebin=tb, user_id=443, timeconstraint=tc)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.024577353020557"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timebin_neighbours_data(ratings, timebin, similar_timebins):\n",
    "    data = defaultdict(list)\n",
    "    for row in similar_timebins.itertuples(index=False):\n",
    "        neighbour_id = row[0]\n",
    "        start_dt = row[1]\n",
    "        timebin_size = row[2]\n",
    "        corr = row[3]\n",
    "        end_dt = start_dt + timedelta(seconds=timebin_size)\n",
    "        timebin_tc = TimeConstraint(start_dt=start_dt, end_dt=end_dt)\n",
    "        neighbour_bin = get_timebin(ratings, user_id=neighbour_id, time_constraint=timebin_tc)\n",
    "        merged_bin = pd.merge(timebin, neighbour_bin, left_index=True, right_index=True)\n",
    "        for bin_row in merged_bin.itertuples(index=True):\n",
    "            curr_movie = bin_row[0]\n",
    "            neighbour_rating = bin_row[3]\n",
    "            #print(bin_row[0], bin_row[1], bin_row[2], bin_row[3], bin_row[4])\n",
    "            data[curr_movie].append( (neighbour_rating, corr) )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_timebin_neighbours_data(dataset.ratings, timebin=tb, similar_timebins=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_movies_watched_using_timebin_neighbours(data, user_id, min_neighbour_count=5):\n",
    "    predictions = list()\n",
    "    for movie_id, rating_corr_list in data.items():\n",
    "        weighted_sum = 0\n",
    "        weight_sum = 0\n",
    "        count = 0\n",
    "        for rating_corr in rating_corr_list:\n",
    "            count += 1\n",
    "            rating = rating_corr[0]\n",
    "            corr = rating_corr[1]\n",
    "            weighted_sum += rating * corr\n",
    "            weight_sum += corr\n",
    "        if count < min_neighbour_count:         # if less than min_neighbour_count neighbour found, pass\n",
    "            continue\n",
    "        prediction = weighted_sum / weight_sum\n",
    "        actual = t.trainset_movie.get_movie_rating(movie_id=movie_id, user_id=user_id)\n",
    "        predictions.append( (prediction, actual) )\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3.9154652826623155, 4.0),\n",
       " (4.695140644695054, 4.5),\n",
       " (4.869577181383489, 4.0),\n",
       " (4.33078315429006, 4.0),\n",
       " (4.890852323386359, 5.0),\n",
       " (4.889431782559287, 5.0),\n",
       " (4.384031184453677, 5.0),\n",
       " (4.6369288051115065, 5.0),\n",
       " (4.436814972732457, 5.0)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_using_timebins = predict_movies_watched_using_timebin_neighbours(data, 443)\n",
    "predictions_using_timebins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19592912827023481"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy.rmse(predictions_using_timebins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal: 1.024577353020557 \t Timebin:0.19592912827023481\n"
     ]
    }
   ],
   "source": [
    "print(f\"Normal: {Accuracy.rmse(predictions)} \\t Timebin:{Accuracy.rmse(predictions_using_timebins)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_normal_and_timebin_predictions(ratings, user_id, time_constraint):\n",
    "    tc = time_constraint\n",
    "    timebin = get_timebin(dataset.ratings, user_id=user_id, time_constraint=tc)\n",
    "    normal_rmse = Accuracy.rmse(predict_movies_watched(timebin=timebin, user_id=user_id, timeconstraint=tc))\n",
    "    \n",
    "    # k -> komşunun en az ortak film sayısı, n -> benzer timebin içindeki en az ortak film sayısı\n",
    "    similar_timebins = get_most_similar_timebins(ratings, user_id,tc, k=5, n=3, corr_threshold=0.5)\n",
    "    data = get_timebin_neighbours_data(ratings, timebin, similar_timebins)\n",
    "    \n",
    "    # En az 'min_neighbour_count' sayıda farklı timebin'den veri gelmediyse o filme tahmin yapma.\n",
    "    predictions = predict_movies_watched_using_timebin_neighbours(data, user_id, min_neighbour_count=5)\n",
    "    \n",
    "    predictions_using_timebins = Accuracy.rmse(predictions)\n",
    "    \n",
    "    print(f\"Normal RMSE: {normal_rmse} \\t Timebin RMSE:{predictions_using_timebins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yukawa\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime=38.806789300000005\n",
      "Normal RMSE: 1.024577353020557 \t Timebin RMSE:0.19592912827023407\n"
     ]
    }
   ],
   "source": [
    "compare_normal_and_timebin_predictions(dataset.ratings, 443, TimeConstraint(start_dt=datetime(year=2017, month=1, day=1), end_dt=datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yukawa\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime=38.046881299999995\n",
      "Normal RMSE: 0.6604464424540253 \t Timebin RMSE:0.5938418606262376\n"
     ]
    }
   ],
   "source": [
    "compare_normal_and_timebin_predictions(dataset.ratings, 610, TimeConstraint(start_dt=datetime(year=2017, month=5, day=3), end_dt=datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_normal_and_timebin_predictions_(ratings, n, s):\n",
    "    \"\"\"\n",
    "    Compare n number of users\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    while count < n:\n",
    "        # Rastgele kullanıcı seç\n",
    "        user_id = random.randint(0,610)\n",
    "        # Rastgele Filmini seç\n",
    "        movie_id = t.trainset_movie.get_random_movie_watched(user_id)\n",
    "        movie_ts = t.trainset_user.get_timestamp(user_id, movie_id)\n",
    "        # Filmi izlemeden önceki s adet filmden olustan timebini al\n",
    "        movies_watched_until_the_movie_ts = get_movies_watched(ratings, user_id, TimeConstraint(end_dt=movie_ts))\n",
    "        if len(movies_watched_until_the_movie_ts) < s:\n",
    "            continue\n",
    "        else:\n",
    "            count += 1\n",
    "        # s inci filmin timestamp i ile baslayip, aradığımız movie_ts ile sonlanan veriyi timebin olarak al\n",
    "        tc = TimeConstraint(start_dt=movies_watched_until_the_movie_ts.iloc[-s]['timestamp'], end_dt=movie_ts)\n",
    "        timebin = get_timebin(dataset.ratings, user_id=user_id, time_constraint=tc)\n",
    "        \n",
    "        # Normal olarak, timebin içinde bulunan tüm filmlere, kullanıcının vereceği puanları tahmin et \n",
    "        normal_rmse = Accuracy.rmse(predict_movies_watched(timebin=timebin, user_id=user_id, timeconstraint=tc))\n",
    "\n",
    "        # k -> komşunun en az ortak film sayısı, n -> benzer timebin içindeki en az ortak film sayısı\n",
    "        similar_timebins = get_most_similar_timebins(ratings, user_id, tc, k=5, n=3)\n",
    "\n",
    "        # Komşuların verilerini topla, bunu yaparken 0.5den aşşağı benzerliği olanları alma.\n",
    "        data = get_timebin_neighbours_data(ratings, timebin, similar_timebins, corr_threshold=0.5)\n",
    "\n",
    "        # En az 'min_neighbour_count' sayıda farklı timebin'den veri gelmediyse o filme tahmin yapma.\n",
    "        predictions = predict_movies_watched_using_timebin_neighbours(data, user_id, min_neighbour_count=5)\n",
    "\n",
    "        predictions_using_timebins = Accuracy.rmse(predictions)\n",
    "\n",
    "        print(f\"Normal RMSE: {normal_rmse} \\t Timebin RMSE:{predictions_using_timebins}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yukawa\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runtime=45.722531000000004\n",
      "Normal RMSE: 0.1503932887861746 \t Timebin RMSE:0.40544615081910407\n",
      "runtime=45.55319700000007\n",
      "Normal RMSE: 0.09246261120125261 \t Timebin RMSE:0.449128347285121\n",
      "runtime=71.1980082\n",
      "Normal RMSE: 0.7753194471566357 \t Timebin RMSE:0.7137459934989867\n",
      "runtime=44.4741798\n",
      "Normal RMSE: 0.49461239586001154 \t Timebin RMSE:0.5545947973703461\n",
      "runtime=44.71568979999995\n",
      "Normal RMSE: 0.10601297823384664 \t Timebin RMSE:0.39214941667097863\n",
      "runtime=56.30889410000009\n",
      "Normal RMSE: 0.02934837375886094 \t Timebin RMSE:0.30137117670610913\n",
      "runtime=90.01689240000007\n",
      "Normal RMSE: 0.5093925950832184 \t Timebin RMSE:0.265049588203881\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Undefined time_constraint is given!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-19b04bf6dc7b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcompare_normal_and_timebin_predictions_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mratings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-44-fa6b8feb3162>\u001b[0m in \u001b[0;36mcompare_normal_and_timebin_predictions_\u001b[1;34m(ratings, n, s)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mmovie_ts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainset_user\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_timestamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmovie_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m# Filmi izlemeden önceki s adet filmden olustan timebini al\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mmovies_watched_until_the_movie_ts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_movies_watched\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTimeConstraint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_dt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmovie_ts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmovies_watched_until_the_movie_ts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-f6312c33bbe7>\u001b[0m in \u001b[0;36mget_movies_watched\u001b[1;34m(ratings, user_id, time_constraint)\u001b[0m\n\u001b[0;32m     20\u001b[0m                                  \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmovie_ratings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimestamp\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mtime_constraint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_dt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                                  & (movie_ratings.timestamp < time_constraint.end_dt)][['item_id', 'rating', 'timestamp']].set_index('item_id')\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Undefined time_constraint is given!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mException\u001b[0m: Undefined time_constraint is given!"
     ]
    }
   ],
   "source": [
    "compare_normal_and_timebin_predictions_(dataset.ratings, n=100, s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mov = get_movies_watched(dataset.ratings, 583)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6764"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.trainset_movie.get_random_movie_watched(610)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.trainset_movie.get_movie_rating(6764, 610)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-05-03 21:28:06')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.trainset_user.get_timestamp(610, 6764)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "548"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randint(0,610)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-11-19 08:08:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2016-11-19 07:56:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2016-11-19 08:15:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-11-19 08:57:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-05-03 20:52:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160527</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2016-11-19 08:43:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160836</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2017-05-03 20:53:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164179</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-05-03 21:07:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168252</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-05-03 21:19:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170875</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2017-05-03 21:20:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rating           timestamp\n",
       "item_id                            \n",
       "1           5.0 2016-11-19 08:08:20\n",
       "16          4.5 2016-11-19 07:56:11\n",
       "32          4.5 2016-11-19 08:15:31\n",
       "47          5.0 2016-11-19 08:57:33\n",
       "50          4.0 2017-05-03 20:52:37\n",
       "...         ...                 ...\n",
       "160527      4.5 2016-11-19 08:43:18\n",
       "160836      3.0 2017-05-03 20:53:14\n",
       "164179      5.0 2017-05-03 21:07:11\n",
       "168252      5.0 2017-05-03 21:19:12\n",
       "170875      3.0 2017-05-03 21:20:15\n",
       "\n",
       "[760 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff = get_movies_watched(dataset.ratings, 610, TimeConstraint(end_dt=t.trainset_user.get_timestamp(610, 6764)))\n",
    "ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-12-11 16:35:36')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff.iloc[-2]['timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8571</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-05-03 21:06:10</td>\n",
       "      <td>116823</td>\n",
       "      <td>The Hunger Games: Mockingjay - Part 1</td>\n",
       "      <td>Adventure|Sci-Fi|Thriller</td>\n",
       "      <td>2014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8577</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2016-11-19 08:31:18</td>\n",
       "      <td>116977</td>\n",
       "      <td>Dumb and Dumber To</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>2014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8589</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2017-05-03 21:15:19</td>\n",
       "      <td>117529</td>\n",
       "      <td>Jurassic World</td>\n",
       "      <td>Action|Adventure|Drama|Sci-Fi|Thriller</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8635</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2017-05-03 21:14:04</td>\n",
       "      <td>119145</td>\n",
       "      <td>Kingsman: The Secret Service</td>\n",
       "      <td>Action|Adventure|Comedy|Crime</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8646</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2017-05-03 21:08:43</td>\n",
       "      <td>120466</td>\n",
       "      <td>Chappie</td>\n",
       "      <td>Action|Thriller</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8653</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2017-05-03 21:10:42</td>\n",
       "      <td>120799</td>\n",
       "      <td>Terminator Genisys</td>\n",
       "      <td>Action|Adventure|Sci-Fi|Thriller</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8680</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-05-03 21:04:04</td>\n",
       "      <td>122882</td>\n",
       "      <td>Mad Max: Fury Road</td>\n",
       "      <td>Action|Adventure|Sci-Fi|Thriller</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8682</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2016-11-19 08:36:29</td>\n",
       "      <td>122886</td>\n",
       "      <td>Star Wars: Episode VII - The Force Awakens</td>\n",
       "      <td>Action|Adventure|Fantasy|Sci-Fi|IMAX</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8685</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2016-11-19 08:03:26</td>\n",
       "      <td>122892</td>\n",
       "      <td>Avengers: Age of Ultron</td>\n",
       "      <td>Action|Adventure|Sci-Fi</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2017-05-03 21:15:26</td>\n",
       "      <td>122900</td>\n",
       "      <td>Ant-Man</td>\n",
       "      <td>Action|Adventure|Sci-Fi</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2017-05-03 21:13:01</td>\n",
       "      <td>122904</td>\n",
       "      <td>Deadpool</td>\n",
       "      <td>Action|Adventure|Comedy|Sci-Fi</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8695</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-05-03 21:07:06</td>\n",
       "      <td>122920</td>\n",
       "      <td>Captain America: Civil War</td>\n",
       "      <td>Action|Sci-Fi|Thriller</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8696</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2017-05-03 21:09:11</td>\n",
       "      <td>122922</td>\n",
       "      <td>Doctor Strange</td>\n",
       "      <td>Action|Adventure|Sci-Fi</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8697</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2017-05-03 21:11:08</td>\n",
       "      <td>122924</td>\n",
       "      <td>X-Men: Apocalypse</td>\n",
       "      <td>Action|Adventure|Fantasy|Sci-Fi</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8782</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2016-11-19 08:13:54</td>\n",
       "      <td>129313</td>\n",
       "      <td>Reality</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>2014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8808</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2017-05-03 21:20:03</td>\n",
       "      <td>130634</td>\n",
       "      <td>Furious 7</td>\n",
       "      <td>Action|Crime|Thriller</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8878</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2016-11-19 08:10:02</td>\n",
       "      <td>134130</td>\n",
       "      <td>The Martian</td>\n",
       "      <td>Adventure|Drama|Sci-Fi</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8889</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2016-11-19 08:05:59</td>\n",
       "      <td>134393</td>\n",
       "      <td>Trainwreck</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8899</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2017-05-03 20:58:26</td>\n",
       "      <td>134853</td>\n",
       "      <td>Inside Out</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Drama|Fantasy</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8903</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-05-03 21:17:17</td>\n",
       "      <td>135133</td>\n",
       "      <td>The Hunger Games: Mockingjay - Part 2</td>\n",
       "      <td>Adventure|Sci-Fi</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8919</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2016-11-19 08:29:20</td>\n",
       "      <td>135803</td>\n",
       "      <td>Five Element Ninjas</td>\n",
       "      <td>Action</td>\n",
       "      <td>1982.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8920</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2016-11-19 08:29:48</td>\n",
       "      <td>135815</td>\n",
       "      <td>The Magnificent Ruffians</td>\n",
       "      <td>Action|Drama</td>\n",
       "      <td>1979.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8926</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2017-05-03 21:23:46</td>\n",
       "      <td>136016</td>\n",
       "      <td>The Good Dinosaur</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8928</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2017-05-03 21:27:43</td>\n",
       "      <td>136020</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>Action|Adventure|Crime</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8973</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2017-05-03 21:18:38</td>\n",
       "      <td>138036</td>\n",
       "      <td>The Man from U.N.C.L.E.</td>\n",
       "      <td>Action|Adventure|Comedy</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8981</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-11-19 08:50:20</td>\n",
       "      <td>138632</td>\n",
       "      <td>Tokyo Tribe</td>\n",
       "      <td>Action|Crime|Drama|Sci-Fi</td>\n",
       "      <td>2014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8989</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2017-05-03 21:26:17</td>\n",
       "      <td>139385</td>\n",
       "      <td>The Revenant</td>\n",
       "      <td>Adventure|Drama</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8991</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2016-11-19 08:50:00</td>\n",
       "      <td>139511</td>\n",
       "      <td>Exte: Hair Extensions</td>\n",
       "      <td>Horror</td>\n",
       "      <td>2007.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8994</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2017-05-03 21:17:33</td>\n",
       "      <td>139644</td>\n",
       "      <td>Sicario</td>\n",
       "      <td>Crime|Drama|Mystery</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9033</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2016-11-19 08:29:30</td>\n",
       "      <td>141400</td>\n",
       "      <td>Invincible Shaolin</td>\n",
       "      <td>Action</td>\n",
       "      <td>1978.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9062</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2016-11-19 08:12:26</td>\n",
       "      <td>142366</td>\n",
       "      <td>Cigarette Burns</td>\n",
       "      <td>Horror|Thriller</td>\n",
       "      <td>2005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9064</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2016-11-19 08:16:52</td>\n",
       "      <td>142420</td>\n",
       "      <td>High Rise</td>\n",
       "      <td>Action|Drama|Sci-Fi</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9096</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2016-11-19 08:32:13</td>\n",
       "      <td>143859</td>\n",
       "      <td>Hail, Caesar!</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9152</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2016-11-19 08:30:10</td>\n",
       "      <td>147657</td>\n",
       "      <td>Masked Avengers</td>\n",
       "      <td>Action</td>\n",
       "      <td>1981.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9153</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2016-11-19 08:30:14</td>\n",
       "      <td>147662</td>\n",
       "      <td>Return of the One-Armed Swordsman</td>\n",
       "      <td>Action|Adventure</td>\n",
       "      <td>1969.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9155</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2016-11-19 07:57:04</td>\n",
       "      <td>148166</td>\n",
       "      <td>Hitchcock/Truffaut</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9183</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2016-11-19 07:58:15</td>\n",
       "      <td>149406</td>\n",
       "      <td>Kung Fu Panda 3</td>\n",
       "      <td>Action|Adventure|Animation</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9191</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2016-11-19 08:13:30</td>\n",
       "      <td>150401</td>\n",
       "      <td>Close Range</td>\n",
       "      <td>Action|Crime</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9220</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-05-03 21:10:17</td>\n",
       "      <td>152077</td>\n",
       "      <td>10 Cloverfield Lane</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9222</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-05-03 21:21:43</td>\n",
       "      <td>152081</td>\n",
       "      <td>Zootopia</td>\n",
       "      <td>Action|Adventure|Animation|Children|Comedy</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9255</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-11-19 08:07:11</td>\n",
       "      <td>156371</td>\n",
       "      <td>Everybody Wants Some</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9273</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-05-03 21:22:43</td>\n",
       "      <td>157296</td>\n",
       "      <td>Finding Dory</td>\n",
       "      <td>Adventure|Animation|Comedy</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9285</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-11-19 08:46:59</td>\n",
       "      <td>158238</td>\n",
       "      <td>The Nice Guys</td>\n",
       "      <td>Crime|Mystery|Thriller</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9291</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2016-11-19 08:01:31</td>\n",
       "      <td>158721</td>\n",
       "      <td>Gen-X Cops</td>\n",
       "      <td>Action|Comedy|Thriller</td>\n",
       "      <td>1999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9324</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2016-11-19 08:55:49</td>\n",
       "      <td>160341</td>\n",
       "      <td>Bloodmoon</td>\n",
       "      <td>Action|Thriller</td>\n",
       "      <td>1997.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9329</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2016-11-19 08:43:18</td>\n",
       "      <td>160527</td>\n",
       "      <td>Sympathy for the Underdog</td>\n",
       "      <td>Action|Crime|Drama</td>\n",
       "      <td>1971.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9341</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2017-05-03 20:53:14</td>\n",
       "      <td>160836</td>\n",
       "      <td>Hazard</td>\n",
       "      <td>Action|Drama|Thriller</td>\n",
       "      <td>2005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9391</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-05-03 21:07:11</td>\n",
       "      <td>164179</td>\n",
       "      <td>Arrival</td>\n",
       "      <td>Sci-Fi</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9462</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-05-03 21:19:12</td>\n",
       "      <td>168252</td>\n",
       "      <td>Logan</td>\n",
       "      <td>Action|Sci-Fi</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9502</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2017-05-03 21:20:15</td>\n",
       "      <td>170875</td>\n",
       "      <td>The Fate of the Furious</td>\n",
       "      <td>Action|Crime|Drama|Thriller</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rating           timestamp  item_id  \\\n",
       "8571     4.0 2017-05-03 21:06:10   116823   \n",
       "8577     3.0 2016-11-19 08:31:18   116977   \n",
       "8589     3.5 2017-05-03 21:15:19   117529   \n",
       "8635     4.5 2017-05-03 21:14:04   119145   \n",
       "8646     3.5 2017-05-03 21:08:43   120466   \n",
       "8653     2.5 2017-05-03 21:10:42   120799   \n",
       "8680     5.0 2017-05-03 21:04:04   122882   \n",
       "8682     4.5 2016-11-19 08:36:29   122886   \n",
       "8685     4.0 2016-11-19 08:03:26   122892   \n",
       "8688     3.5 2017-05-03 21:15:26   122900   \n",
       "8690     3.0 2017-05-03 21:13:01   122904   \n",
       "8695     5.0 2017-05-03 21:07:06   122920   \n",
       "8696     3.5 2017-05-03 21:09:11   122922   \n",
       "8697     3.5 2017-05-03 21:11:08   122924   \n",
       "8782     4.0 2016-11-19 08:13:54   129313   \n",
       "8808     4.5 2017-05-03 21:20:03   130634   \n",
       "8878     3.5 2016-11-19 08:10:02   134130   \n",
       "8889     3.5 2016-11-19 08:05:59   134393   \n",
       "8899     3.5 2017-05-03 20:58:26   134853   \n",
       "8903     4.0 2017-05-03 21:17:17   135133   \n",
       "8919     3.5 2016-11-19 08:29:20   135803   \n",
       "8920     4.0 2016-11-19 08:29:48   135815   \n",
       "8926     3.5 2017-05-03 21:23:46   136016   \n",
       "8928     3.5 2017-05-03 21:27:43   136020   \n",
       "8973     3.5 2017-05-03 21:18:38   138036   \n",
       "8981     5.0 2016-11-19 08:50:20   138632   \n",
       "8989     4.5 2017-05-03 21:26:17   139385   \n",
       "8991     3.0 2016-11-19 08:50:00   139511   \n",
       "8994     4.5 2017-05-03 21:17:33   139644   \n",
       "9033     4.0 2016-11-19 08:29:30   141400   \n",
       "9062     3.0 2016-11-19 08:12:26   142366   \n",
       "9064     3.5 2016-11-19 08:16:52   142420   \n",
       "9096     4.0 2016-11-19 08:32:13   143859   \n",
       "9152     4.0 2016-11-19 08:30:10   147657   \n",
       "9153     3.0 2016-11-19 08:30:14   147662   \n",
       "9155     3.5 2016-11-19 07:57:04   148166   \n",
       "9183     3.5 2016-11-19 07:58:15   149406   \n",
       "9191     3.0 2016-11-19 08:13:30   150401   \n",
       "9220     4.0 2017-05-03 21:10:17   152077   \n",
       "9222     4.0 2017-05-03 21:21:43   152081   \n",
       "9255     5.0 2016-11-19 08:07:11   156371   \n",
       "9273     4.0 2017-05-03 21:22:43   157296   \n",
       "9285     5.0 2016-11-19 08:46:59   158238   \n",
       "9291     3.5 2016-11-19 08:01:31   158721   \n",
       "9324     2.5 2016-11-19 08:55:49   160341   \n",
       "9329     4.5 2016-11-19 08:43:18   160527   \n",
       "9341     3.0 2017-05-03 20:53:14   160836   \n",
       "9391     5.0 2017-05-03 21:07:11   164179   \n",
       "9462     5.0 2017-05-03 21:19:12   168252   \n",
       "9502     3.0 2017-05-03 21:20:15   170875   \n",
       "\n",
       "                                           title  \\\n",
       "8571       The Hunger Games: Mockingjay - Part 1   \n",
       "8577                          Dumb and Dumber To   \n",
       "8589                              Jurassic World   \n",
       "8635                Kingsman: The Secret Service   \n",
       "8646                                     Chappie   \n",
       "8653                          Terminator Genisys   \n",
       "8680                          Mad Max: Fury Road   \n",
       "8682  Star Wars: Episode VII - The Force Awakens   \n",
       "8685                     Avengers: Age of Ultron   \n",
       "8688                                     Ant-Man   \n",
       "8690                                    Deadpool   \n",
       "8695                  Captain America: Civil War   \n",
       "8696                              Doctor Strange   \n",
       "8697                           X-Men: Apocalypse   \n",
       "8782                                     Reality   \n",
       "8808                                   Furious 7   \n",
       "8878                                 The Martian   \n",
       "8889                                  Trainwreck   \n",
       "8899                                  Inside Out   \n",
       "8903       The Hunger Games: Mockingjay - Part 2   \n",
       "8919                         Five Element Ninjas   \n",
       "8920                    The Magnificent Ruffians   \n",
       "8926                           The Good Dinosaur   \n",
       "8928                                     Spectre   \n",
       "8973                     The Man from U.N.C.L.E.   \n",
       "8981                                 Tokyo Tribe   \n",
       "8989                                The Revenant   \n",
       "8991                       Exte: Hair Extensions   \n",
       "8994                                     Sicario   \n",
       "9033                          Invincible Shaolin   \n",
       "9062                             Cigarette Burns   \n",
       "9064                                   High Rise   \n",
       "9096                               Hail, Caesar!   \n",
       "9152                             Masked Avengers   \n",
       "9153           Return of the One-Armed Swordsman   \n",
       "9155                          Hitchcock/Truffaut   \n",
       "9183                             Kung Fu Panda 3   \n",
       "9191                                 Close Range   \n",
       "9220                         10 Cloverfield Lane   \n",
       "9222                                    Zootopia   \n",
       "9255                        Everybody Wants Some   \n",
       "9273                                Finding Dory   \n",
       "9285                               The Nice Guys   \n",
       "9291                                  Gen-X Cops   \n",
       "9324                                   Bloodmoon   \n",
       "9329                   Sympathy for the Underdog   \n",
       "9341                                      Hazard   \n",
       "9391                                     Arrival   \n",
       "9462                                       Logan   \n",
       "9502                     The Fate of the Furious   \n",
       "\n",
       "                                                 genres    year  \n",
       "8571                          Adventure|Sci-Fi|Thriller  2014.0  \n",
       "8577                                             Comedy  2014.0  \n",
       "8589             Action|Adventure|Drama|Sci-Fi|Thriller  2015.0  \n",
       "8635                      Action|Adventure|Comedy|Crime  2015.0  \n",
       "8646                                    Action|Thriller  2015.0  \n",
       "8653                   Action|Adventure|Sci-Fi|Thriller  2015.0  \n",
       "8680                   Action|Adventure|Sci-Fi|Thriller  2015.0  \n",
       "8682               Action|Adventure|Fantasy|Sci-Fi|IMAX  2015.0  \n",
       "8685                            Action|Adventure|Sci-Fi  2015.0  \n",
       "8688                            Action|Adventure|Sci-Fi  2015.0  \n",
       "8690                     Action|Adventure|Comedy|Sci-Fi  2016.0  \n",
       "8695                             Action|Sci-Fi|Thriller  2016.0  \n",
       "8696                            Action|Adventure|Sci-Fi  2016.0  \n",
       "8697                    Action|Adventure|Fantasy|Sci-Fi  2016.0  \n",
       "8782                                             Comedy  2014.0  \n",
       "8808                              Action|Crime|Thriller  2015.0  \n",
       "8878                             Adventure|Drama|Sci-Fi  2015.0  \n",
       "8889                                     Comedy|Romance  2015.0  \n",
       "8899  Adventure|Animation|Children|Comedy|Drama|Fantasy  2015.0  \n",
       "8903                                   Adventure|Sci-Fi  2015.0  \n",
       "8919                                             Action  1982.0  \n",
       "8920                                       Action|Drama  1979.0  \n",
       "8926        Adventure|Animation|Children|Comedy|Fantasy  2015.0  \n",
       "8928                             Action|Adventure|Crime  2015.0  \n",
       "8973                            Action|Adventure|Comedy  2015.0  \n",
       "8981                          Action|Crime|Drama|Sci-Fi  2014.0  \n",
       "8989                                    Adventure|Drama  2015.0  \n",
       "8991                                             Horror  2007.0  \n",
       "8994                                Crime|Drama|Mystery  2015.0  \n",
       "9033                                             Action  1978.0  \n",
       "9062                                    Horror|Thriller  2005.0  \n",
       "9064                                Action|Drama|Sci-Fi  2015.0  \n",
       "9096                                             Comedy  2016.0  \n",
       "9152                                             Action  1981.0  \n",
       "9153                                   Action|Adventure  1969.0  \n",
       "9155                                        Documentary  2015.0  \n",
       "9183                         Action|Adventure|Animation  2016.0  \n",
       "9191                                       Action|Crime  2015.0  \n",
       "9220                                           Thriller  2016.0  \n",
       "9222         Action|Adventure|Animation|Children|Comedy  2016.0  \n",
       "9255                                             Comedy  2016.0  \n",
       "9273                         Adventure|Animation|Comedy  2016.0  \n",
       "9285                             Crime|Mystery|Thriller  2016.0  \n",
       "9291                             Action|Comedy|Thriller  1999.0  \n",
       "9324                                    Action|Thriller  1997.0  \n",
       "9329                                 Action|Crime|Drama  1971.0  \n",
       "9341                              Action|Drama|Thriller  2005.0  \n",
       "9391                                             Sci-Fi  2016.0  \n",
       "9462                                      Action|Sci-Fi  2017.0  \n",
       "9502                        Action|Crime|Drama|Thriller  2017.0  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd = pd.merge(ff, dataset.movies, left_index=True, right_on='item_id').iloc[-50:]\n",
    "fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8571</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-05-03 21:06:10</td>\n",
       "      <td>116823</td>\n",
       "      <td>The Hunger Games: Mockingjay - Part 1</td>\n",
       "      <td>Adventure|Sci-Fi|Thriller</td>\n",
       "      <td>2014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8577</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2016-11-19 08:31:18</td>\n",
       "      <td>116977</td>\n",
       "      <td>Dumb and Dumber To</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>2014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8589</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2017-05-03 21:15:19</td>\n",
       "      <td>117529</td>\n",
       "      <td>Jurassic World</td>\n",
       "      <td>Action|Adventure|Drama|Sci-Fi|Thriller</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8635</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2017-05-03 21:14:04</td>\n",
       "      <td>119145</td>\n",
       "      <td>Kingsman: The Secret Service</td>\n",
       "      <td>Action|Adventure|Comedy|Crime</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8646</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2017-05-03 21:08:43</td>\n",
       "      <td>120466</td>\n",
       "      <td>Chappie</td>\n",
       "      <td>Action|Thriller</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8653</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2017-05-03 21:10:42</td>\n",
       "      <td>120799</td>\n",
       "      <td>Terminator Genisys</td>\n",
       "      <td>Action|Adventure|Sci-Fi|Thriller</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8680</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-05-03 21:04:04</td>\n",
       "      <td>122882</td>\n",
       "      <td>Mad Max: Fury Road</td>\n",
       "      <td>Action|Adventure|Sci-Fi|Thriller</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8682</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2016-11-19 08:36:29</td>\n",
       "      <td>122886</td>\n",
       "      <td>Star Wars: Episode VII - The Force Awakens</td>\n",
       "      <td>Action|Adventure|Fantasy|Sci-Fi|IMAX</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8685</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2016-11-19 08:03:26</td>\n",
       "      <td>122892</td>\n",
       "      <td>Avengers: Age of Ultron</td>\n",
       "      <td>Action|Adventure|Sci-Fi</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2017-05-03 21:15:26</td>\n",
       "      <td>122900</td>\n",
       "      <td>Ant-Man</td>\n",
       "      <td>Action|Adventure|Sci-Fi</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2017-05-03 21:13:01</td>\n",
       "      <td>122904</td>\n",
       "      <td>Deadpool</td>\n",
       "      <td>Action|Adventure|Comedy|Sci-Fi</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8695</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-05-03 21:07:06</td>\n",
       "      <td>122920</td>\n",
       "      <td>Captain America: Civil War</td>\n",
       "      <td>Action|Sci-Fi|Thriller</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8696</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2017-05-03 21:09:11</td>\n",
       "      <td>122922</td>\n",
       "      <td>Doctor Strange</td>\n",
       "      <td>Action|Adventure|Sci-Fi</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8697</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2017-05-03 21:11:08</td>\n",
       "      <td>122924</td>\n",
       "      <td>X-Men: Apocalypse</td>\n",
       "      <td>Action|Adventure|Fantasy|Sci-Fi</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8782</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2016-11-19 08:13:54</td>\n",
       "      <td>129313</td>\n",
       "      <td>Reality</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>2014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8808</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2017-05-03 21:20:03</td>\n",
       "      <td>130634</td>\n",
       "      <td>Furious 7</td>\n",
       "      <td>Action|Crime|Thriller</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8878</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2016-11-19 08:10:02</td>\n",
       "      <td>134130</td>\n",
       "      <td>The Martian</td>\n",
       "      <td>Adventure|Drama|Sci-Fi</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8889</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2016-11-19 08:05:59</td>\n",
       "      <td>134393</td>\n",
       "      <td>Trainwreck</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8899</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2017-05-03 20:58:26</td>\n",
       "      <td>134853</td>\n",
       "      <td>Inside Out</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Drama|Fantasy</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8903</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-05-03 21:17:17</td>\n",
       "      <td>135133</td>\n",
       "      <td>The Hunger Games: Mockingjay - Part 2</td>\n",
       "      <td>Adventure|Sci-Fi</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8919</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2016-11-19 08:29:20</td>\n",
       "      <td>135803</td>\n",
       "      <td>Five Element Ninjas</td>\n",
       "      <td>Action</td>\n",
       "      <td>1982.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8920</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2016-11-19 08:29:48</td>\n",
       "      <td>135815</td>\n",
       "      <td>The Magnificent Ruffians</td>\n",
       "      <td>Action|Drama</td>\n",
       "      <td>1979.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8926</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2017-05-03 21:23:46</td>\n",
       "      <td>136016</td>\n",
       "      <td>The Good Dinosaur</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8928</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2017-05-03 21:27:43</td>\n",
       "      <td>136020</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>Action|Adventure|Crime</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8973</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2017-05-03 21:18:38</td>\n",
       "      <td>138036</td>\n",
       "      <td>The Man from U.N.C.L.E.</td>\n",
       "      <td>Action|Adventure|Comedy</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8981</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-11-19 08:50:20</td>\n",
       "      <td>138632</td>\n",
       "      <td>Tokyo Tribe</td>\n",
       "      <td>Action|Crime|Drama|Sci-Fi</td>\n",
       "      <td>2014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8989</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2017-05-03 21:26:17</td>\n",
       "      <td>139385</td>\n",
       "      <td>The Revenant</td>\n",
       "      <td>Adventure|Drama</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8991</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2016-11-19 08:50:00</td>\n",
       "      <td>139511</td>\n",
       "      <td>Exte: Hair Extensions</td>\n",
       "      <td>Horror</td>\n",
       "      <td>2007.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8994</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2017-05-03 21:17:33</td>\n",
       "      <td>139644</td>\n",
       "      <td>Sicario</td>\n",
       "      <td>Crime|Drama|Mystery</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9033</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2016-11-19 08:29:30</td>\n",
       "      <td>141400</td>\n",
       "      <td>Invincible Shaolin</td>\n",
       "      <td>Action</td>\n",
       "      <td>1978.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9062</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2016-11-19 08:12:26</td>\n",
       "      <td>142366</td>\n",
       "      <td>Cigarette Burns</td>\n",
       "      <td>Horror|Thriller</td>\n",
       "      <td>2005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9064</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2016-11-19 08:16:52</td>\n",
       "      <td>142420</td>\n",
       "      <td>High Rise</td>\n",
       "      <td>Action|Drama|Sci-Fi</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9096</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2016-11-19 08:32:13</td>\n",
       "      <td>143859</td>\n",
       "      <td>Hail, Caesar!</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9152</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2016-11-19 08:30:10</td>\n",
       "      <td>147657</td>\n",
       "      <td>Masked Avengers</td>\n",
       "      <td>Action</td>\n",
       "      <td>1981.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9153</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2016-11-19 08:30:14</td>\n",
       "      <td>147662</td>\n",
       "      <td>Return of the One-Armed Swordsman</td>\n",
       "      <td>Action|Adventure</td>\n",
       "      <td>1969.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9155</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2016-11-19 07:57:04</td>\n",
       "      <td>148166</td>\n",
       "      <td>Hitchcock/Truffaut</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9183</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2016-11-19 07:58:15</td>\n",
       "      <td>149406</td>\n",
       "      <td>Kung Fu Panda 3</td>\n",
       "      <td>Action|Adventure|Animation</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9191</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2016-11-19 08:13:30</td>\n",
       "      <td>150401</td>\n",
       "      <td>Close Range</td>\n",
       "      <td>Action|Crime</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9220</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-05-03 21:10:17</td>\n",
       "      <td>152077</td>\n",
       "      <td>10 Cloverfield Lane</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9222</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-05-03 21:21:43</td>\n",
       "      <td>152081</td>\n",
       "      <td>Zootopia</td>\n",
       "      <td>Action|Adventure|Animation|Children|Comedy</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9255</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-11-19 08:07:11</td>\n",
       "      <td>156371</td>\n",
       "      <td>Everybody Wants Some</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9273</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-05-03 21:22:43</td>\n",
       "      <td>157296</td>\n",
       "      <td>Finding Dory</td>\n",
       "      <td>Adventure|Animation|Comedy</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9285</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-11-19 08:46:59</td>\n",
       "      <td>158238</td>\n",
       "      <td>The Nice Guys</td>\n",
       "      <td>Crime|Mystery|Thriller</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9291</th>\n",
       "      <td>3.5</td>\n",
       "      <td>2016-11-19 08:01:31</td>\n",
       "      <td>158721</td>\n",
       "      <td>Gen-X Cops</td>\n",
       "      <td>Action|Comedy|Thriller</td>\n",
       "      <td>1999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9324</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2016-11-19 08:55:49</td>\n",
       "      <td>160341</td>\n",
       "      <td>Bloodmoon</td>\n",
       "      <td>Action|Thriller</td>\n",
       "      <td>1997.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9329</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2016-11-19 08:43:18</td>\n",
       "      <td>160527</td>\n",
       "      <td>Sympathy for the Underdog</td>\n",
       "      <td>Action|Crime|Drama</td>\n",
       "      <td>1971.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9341</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2017-05-03 20:53:14</td>\n",
       "      <td>160836</td>\n",
       "      <td>Hazard</td>\n",
       "      <td>Action|Drama|Thriller</td>\n",
       "      <td>2005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9391</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-05-03 21:07:11</td>\n",
       "      <td>164179</td>\n",
       "      <td>Arrival</td>\n",
       "      <td>Sci-Fi</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9462</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-05-03 21:19:12</td>\n",
       "      <td>168252</td>\n",
       "      <td>Logan</td>\n",
       "      <td>Action|Sci-Fi</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9502</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2017-05-03 21:20:15</td>\n",
       "      <td>170875</td>\n",
       "      <td>The Fate of the Furious</td>\n",
       "      <td>Action|Crime|Drama|Thriller</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rating           timestamp  item_id  \\\n",
       "8571     4.0 2017-05-03 21:06:10   116823   \n",
       "8577     3.0 2016-11-19 08:31:18   116977   \n",
       "8589     3.5 2017-05-03 21:15:19   117529   \n",
       "8635     4.5 2017-05-03 21:14:04   119145   \n",
       "8646     3.5 2017-05-03 21:08:43   120466   \n",
       "8653     2.5 2017-05-03 21:10:42   120799   \n",
       "8680     5.0 2017-05-03 21:04:04   122882   \n",
       "8682     4.5 2016-11-19 08:36:29   122886   \n",
       "8685     4.0 2016-11-19 08:03:26   122892   \n",
       "8688     3.5 2017-05-03 21:15:26   122900   \n",
       "8690     3.0 2017-05-03 21:13:01   122904   \n",
       "8695     5.0 2017-05-03 21:07:06   122920   \n",
       "8696     3.5 2017-05-03 21:09:11   122922   \n",
       "8697     3.5 2017-05-03 21:11:08   122924   \n",
       "8782     4.0 2016-11-19 08:13:54   129313   \n",
       "8808     4.5 2017-05-03 21:20:03   130634   \n",
       "8878     3.5 2016-11-19 08:10:02   134130   \n",
       "8889     3.5 2016-11-19 08:05:59   134393   \n",
       "8899     3.5 2017-05-03 20:58:26   134853   \n",
       "8903     4.0 2017-05-03 21:17:17   135133   \n",
       "8919     3.5 2016-11-19 08:29:20   135803   \n",
       "8920     4.0 2016-11-19 08:29:48   135815   \n",
       "8926     3.5 2017-05-03 21:23:46   136016   \n",
       "8928     3.5 2017-05-03 21:27:43   136020   \n",
       "8973     3.5 2017-05-03 21:18:38   138036   \n",
       "8981     5.0 2016-11-19 08:50:20   138632   \n",
       "8989     4.5 2017-05-03 21:26:17   139385   \n",
       "8991     3.0 2016-11-19 08:50:00   139511   \n",
       "8994     4.5 2017-05-03 21:17:33   139644   \n",
       "9033     4.0 2016-11-19 08:29:30   141400   \n",
       "9062     3.0 2016-11-19 08:12:26   142366   \n",
       "9064     3.5 2016-11-19 08:16:52   142420   \n",
       "9096     4.0 2016-11-19 08:32:13   143859   \n",
       "9152     4.0 2016-11-19 08:30:10   147657   \n",
       "9153     3.0 2016-11-19 08:30:14   147662   \n",
       "9155     3.5 2016-11-19 07:57:04   148166   \n",
       "9183     3.5 2016-11-19 07:58:15   149406   \n",
       "9191     3.0 2016-11-19 08:13:30   150401   \n",
       "9220     4.0 2017-05-03 21:10:17   152077   \n",
       "9222     4.0 2017-05-03 21:21:43   152081   \n",
       "9255     5.0 2016-11-19 08:07:11   156371   \n",
       "9273     4.0 2017-05-03 21:22:43   157296   \n",
       "9285     5.0 2016-11-19 08:46:59   158238   \n",
       "9291     3.5 2016-11-19 08:01:31   158721   \n",
       "9324     2.5 2016-11-19 08:55:49   160341   \n",
       "9329     4.5 2016-11-19 08:43:18   160527   \n",
       "9341     3.0 2017-05-03 20:53:14   160836   \n",
       "9391     5.0 2017-05-03 21:07:11   164179   \n",
       "9462     5.0 2017-05-03 21:19:12   168252   \n",
       "9502     3.0 2017-05-03 21:20:15   170875   \n",
       "\n",
       "                                           title  \\\n",
       "8571       The Hunger Games: Mockingjay - Part 1   \n",
       "8577                          Dumb and Dumber To   \n",
       "8589                              Jurassic World   \n",
       "8635                Kingsman: The Secret Service   \n",
       "8646                                     Chappie   \n",
       "8653                          Terminator Genisys   \n",
       "8680                          Mad Max: Fury Road   \n",
       "8682  Star Wars: Episode VII - The Force Awakens   \n",
       "8685                     Avengers: Age of Ultron   \n",
       "8688                                     Ant-Man   \n",
       "8690                                    Deadpool   \n",
       "8695                  Captain America: Civil War   \n",
       "8696                              Doctor Strange   \n",
       "8697                           X-Men: Apocalypse   \n",
       "8782                                     Reality   \n",
       "8808                                   Furious 7   \n",
       "8878                                 The Martian   \n",
       "8889                                  Trainwreck   \n",
       "8899                                  Inside Out   \n",
       "8903       The Hunger Games: Mockingjay - Part 2   \n",
       "8919                         Five Element Ninjas   \n",
       "8920                    The Magnificent Ruffians   \n",
       "8926                           The Good Dinosaur   \n",
       "8928                                     Spectre   \n",
       "8973                     The Man from U.N.C.L.E.   \n",
       "8981                                 Tokyo Tribe   \n",
       "8989                                The Revenant   \n",
       "8991                       Exte: Hair Extensions   \n",
       "8994                                     Sicario   \n",
       "9033                          Invincible Shaolin   \n",
       "9062                             Cigarette Burns   \n",
       "9064                                   High Rise   \n",
       "9096                               Hail, Caesar!   \n",
       "9152                             Masked Avengers   \n",
       "9153           Return of the One-Armed Swordsman   \n",
       "9155                          Hitchcock/Truffaut   \n",
       "9183                             Kung Fu Panda 3   \n",
       "9191                                 Close Range   \n",
       "9220                         10 Cloverfield Lane   \n",
       "9222                                    Zootopia   \n",
       "9255                        Everybody Wants Some   \n",
       "9273                                Finding Dory   \n",
       "9285                               The Nice Guys   \n",
       "9291                                  Gen-X Cops   \n",
       "9324                                   Bloodmoon   \n",
       "9329                   Sympathy for the Underdog   \n",
       "9341                                      Hazard   \n",
       "9391                                     Arrival   \n",
       "9462                                       Logan   \n",
       "9502                     The Fate of the Furious   \n",
       "\n",
       "                                                 genres    year  \n",
       "8571                          Adventure|Sci-Fi|Thriller  2014.0  \n",
       "8577                                             Comedy  2014.0  \n",
       "8589             Action|Adventure|Drama|Sci-Fi|Thriller  2015.0  \n",
       "8635                      Action|Adventure|Comedy|Crime  2015.0  \n",
       "8646                                    Action|Thriller  2015.0  \n",
       "8653                   Action|Adventure|Sci-Fi|Thriller  2015.0  \n",
       "8680                   Action|Adventure|Sci-Fi|Thriller  2015.0  \n",
       "8682               Action|Adventure|Fantasy|Sci-Fi|IMAX  2015.0  \n",
       "8685                            Action|Adventure|Sci-Fi  2015.0  \n",
       "8688                            Action|Adventure|Sci-Fi  2015.0  \n",
       "8690                     Action|Adventure|Comedy|Sci-Fi  2016.0  \n",
       "8695                             Action|Sci-Fi|Thriller  2016.0  \n",
       "8696                            Action|Adventure|Sci-Fi  2016.0  \n",
       "8697                    Action|Adventure|Fantasy|Sci-Fi  2016.0  \n",
       "8782                                             Comedy  2014.0  \n",
       "8808                              Action|Crime|Thriller  2015.0  \n",
       "8878                             Adventure|Drama|Sci-Fi  2015.0  \n",
       "8889                                     Comedy|Romance  2015.0  \n",
       "8899  Adventure|Animation|Children|Comedy|Drama|Fantasy  2015.0  \n",
       "8903                                   Adventure|Sci-Fi  2015.0  \n",
       "8919                                             Action  1982.0  \n",
       "8920                                       Action|Drama  1979.0  \n",
       "8926        Adventure|Animation|Children|Comedy|Fantasy  2015.0  \n",
       "8928                             Action|Adventure|Crime  2015.0  \n",
       "8973                            Action|Adventure|Comedy  2015.0  \n",
       "8981                          Action|Crime|Drama|Sci-Fi  2014.0  \n",
       "8989                                    Adventure|Drama  2015.0  \n",
       "8991                                             Horror  2007.0  \n",
       "8994                                Crime|Drama|Mystery  2015.0  \n",
       "9033                                             Action  1978.0  \n",
       "9062                                    Horror|Thriller  2005.0  \n",
       "9064                                Action|Drama|Sci-Fi  2015.0  \n",
       "9096                                             Comedy  2016.0  \n",
       "9152                                             Action  1981.0  \n",
       "9153                                   Action|Adventure  1969.0  \n",
       "9155                                        Documentary  2015.0  \n",
       "9183                         Action|Adventure|Animation  2016.0  \n",
       "9191                                       Action|Crime  2015.0  \n",
       "9220                                           Thriller  2016.0  \n",
       "9222         Action|Adventure|Animation|Children|Comedy  2016.0  \n",
       "9255                                             Comedy  2016.0  \n",
       "9273                         Adventure|Animation|Comedy  2016.0  \n",
       "9285                             Crime|Mystery|Thriller  2016.0  \n",
       "9291                             Action|Comedy|Thriller  1999.0  \n",
       "9324                                    Action|Thriller  1997.0  \n",
       "9329                                 Action|Crime|Drama  1971.0  \n",
       "9341                              Action|Drama|Thriller  2005.0  \n",
       "9391                                             Sci-Fi  2016.0  \n",
       "9462                                      Action|Sci-Fi  2017.0  \n",
       "9502                        Action|Crime|Drama|Thriller  2017.0  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = abs(datetime(2015,5,5) - datetime(2020,5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157852800.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sss.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sss + timedelta(seconds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157852810.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
